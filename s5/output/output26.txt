utils/copy_data_dir.sh: copied data from data/train to data/train_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_hires
utils/data/perturb_data_dir_volume.sh: data/train_hires/feats.scp exists; moving it to data/train_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_hires
steps/make_mfcc.sh --nj 5 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/train_hires exp/make_hires/train mfcc_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_hires
steps/compute_cmvn_stats.sh data/train_hires exp/make_hires/train mfcc_hires
Succeeded creating CMVN stats for train_hires
fix_data_dir.sh: kept all 4758 utterances.
fix_data_dir.sh: old files are kept in data/train_hires/.backup
utils/copy_data_dir.sh: copied data from data/dev to data/dev_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_hires
steps/make_mfcc.sh --cmd run.pl --nj 5 --mfcc-config conf/mfcc_hires.conf data/dev_hires exp/make_hires/dev mfcc_hires
steps/make_mfcc.sh: moving data/dev_hires/feats.scp to data/dev_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for dev_hires
steps/compute_cmvn_stats.sh data/dev_hires exp/make_hires/dev mfcc_hires
Succeeded creating CMVN stats for dev_hires
fix_data_dir.sh: kept all 1056 utterances.
fix_data_dir.sh: old files are kept in data/dev_hires/.backup
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh --cmd run.pl --nj 5 --mfcc-config conf/mfcc_hires.conf data/test_hires exp/make_hires/test mfcc_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires exp/make_hires/test mfcc_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 908 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
utils/subset_data_dir.sh: reducing #utt from 4758 to 500
steps/train_lda_mllt.sh --cmd run.pl --num-iters 13 --splice-opts --left-context=3 --right-context=3 5500 90000 data/train_hires data/lang exp/tri2b_ali exp/nnet3_vp/tri3b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
steps/train_lda_mllt.sh: Converting alignments from exp/tri2b_ali to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/nnet3_vp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/nnet3_vp/tri3b/log/analyze_alignments.log
2 warnings in exp/nnet3_vp/tri3b/log/lda_acc.*.log
24 warnings in exp/nnet3_vp/tri3b/log/acc.*.*.log
1 warnings in exp/nnet3_vp/tri3b/log/build_tree.log
1113 warnings in exp/nnet3_vp/tri3b/log/update.*.log
47 warnings in exp/nnet3_vp/tri3b/log/align.*.*.log
1192 warnings in exp/nnet3_vp/tri3b/log/init_model.log
exp/nnet3_vp/tri3b: nj=5 align prob=-46.84 over 4.75h [retry=0.9%, fail=0.0%] states=3944 gauss=42732 tree-impr=5.12 lda-sum=19.90 mllt:impr,logdet=1.22,2.55
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/nnet3_vp/tri3b
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --nj 5 --num-frames 200000 data/train_10k_hires 512 exp/nnet3_vp/tri3b exp/nnet3_vp/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3_vp/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3_vp/diag_ubm/backup.63K
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 200000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 5 machines, parallelized with 'run.pl'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --nj 5 data/train_hires exp/nnet3_vp/diag_ubm exp/nnet3_vp/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_hires to data/train_max2_hires, number of speakers changed from 41 to 2386
utils/validate_data_dir.sh: Successfully validated data-directory data/train_max2_hires
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 5 data/train_max2_hires exp/nnet3_vp/extractor exp/nnet3_vp/ivectors_train
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_vp/ivectors_train using the extractor in exp/nnet3_vp/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 5 data/dev_hires exp/nnet3_vp/extractor exp/nnet3_vp/ivectors_dev
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_vp/ivectors_dev using the extractor in exp/nnet3_vp/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 5 data/test_hires exp/nnet3_vp/extractor exp/nnet3_vp/ivectors_test
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_vp/ivectors_test using the extractor in exp/nnet3_vp/extractor.
local/nnet3/run_tdnn_delta.sh: creating neural net configs using the xconfig parser
tree-info exp/tri3b_ali/tree 
nnet3-init exp/nnet3_vp/tdnn/configs//ref.config exp/nnet3_vp/tdnn/configs//ref.raw 
LOG (nnet3-init[5.5.608~1-23868]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3_vp/tdnn/configs//ref.raw
nnet3-info exp/nnet3_vp/tdnn/configs//ref.raw 
nnet3-init exp/nnet3_vp/tdnn/configs//ref.config exp/nnet3_vp/tdnn/configs//ref.raw 
LOG (nnet3-init[5.5.608~1-23868]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3_vp/tdnn/configs//ref.raw
nnet3-info exp/nnet3_vp/tdnn/configs//ref.raw 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3_vp/tdnn/configs/network.xconfig --config-dir exp/nnet3_vp/tdnn/configs/
2020-02-12 09:17:39,292 [steps/nnet3/train_dnn.py:36 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --feat.online-ivector-dir exp/nnet3_vp/ivectors_train --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial 1 --trainer.optimization.num-jobs-final 2 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --trainer.optimization.do-final-combination true --egs.dir  --cleanup.remove-egs true --cleanup.preserve-model-interval 100 --use-gpu wait --feat-dir=data/train_hires --ali-dir exp/tri3b_ali --lang data/lang --reporting.email= --dir=exp/nnet3_vp/tdnn
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl', '--feat.online-ivector-dir', 'exp/nnet3_vp/ivectors_train', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial', '1', '--trainer.optimization.num-jobs-final', '2', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--trainer.optimization.do-final-combination', 'true', '--egs.dir', '', '--cleanup.remove-egs', 'true', '--cleanup.preserve-model-interval', '100', '--use-gpu', 'wait', '--feat-dir=data/train_hires', '--ali-dir', 'exp/tri3b_ali', '--lang', 'data/lang', '--reporting.email=', '--dir=exp/nnet3_vp/tdnn']
2020-02-12 09:17:39,348 [steps/nnet3/train_dnn.py:178 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri3b_ali',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3_vp/tdnn',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': None,
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 4,
 'initial_effective_lrate': 0.0017,
 'input_model': None,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 2,
 'num_jobs_initial': 1,
 'num_jobs_step': 1,
 'online_ivector_dir': 'exp/nnet3_vp/ivectors_train',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': [],
 'use_gpu': 'wait'}
2020-02-12 09:17:39,437 [steps/nnet3/train_dnn.py:238 - train - INFO ] Generating egs
steps/nnet3/get_egs.sh --cmd run.pl --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3_vp/ivectors_train --left-context 18 --right-context 14 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 4 --srand 0 data/train_hires exp/tri3b_ali exp/nnet3_vp/tdnn/egs
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3_vp/tdnn/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
feat-to-dim scp:exp/nnet3_vp/ivectors_train/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: creating 2 archives, each with 214794 egs, with
steps/nnet3/get_egs.sh:   4 labels per example, and (left,right) context = (18,14)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3_vp/tdnn/egs/ali.ark,exp/nnet3_vp/tdnn/egs/ali.scp 
LOG (copy-int-vector[5.5.608~1-23868]:main():copy-int-vector.cc:83) Copied 4755 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
2020-02-12 09:17:57,340 [steps/nnet3/train_dnn.py:287 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2020-02-12 09:17:57,779 [steps/nnet3/train_dnn.py:294 - train - INFO ] Preparing the initial acoustic model.
2020-02-12 09:17:58,848 [steps/nnet3/train_dnn.py:319 - train - INFO ] Training will run for 2.0 epochs = 10 iterations
2020-02-12 09:17:58,848 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 0/9   Jobs: 1   Epoch: 0.00/2.0 (0.0% complete)   lr: 0.001700   
2020-02-12 09:18:10,541 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 1/9   Jobs: 1   Epoch: 0.12/2.0 (6.2% complete)   lr: 0.001472   
2020-02-12 09:18:21,085 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 2/9   Jobs: 1   Epoch: 0.25/2.0 (12.5% complete)   lr: 0.001275   
2020-02-12 09:18:31,422 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 3/9   Jobs: 1   Epoch: 0.38/2.0 (18.8% complete)   lr: 0.001104   
2020-02-12 09:18:42,058 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 4/9   Jobs: 1   Epoch: 0.50/2.0 (25.0% complete)   lr: 0.000956   
2020-02-12 09:18:52,719 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 5/9   Jobs: 2   Epoch: 0.62/2.0 (31.2% complete)   lr: 0.001656   
2020-02-12 09:19:03,620 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 6/9   Jobs: 2   Epoch: 0.88/2.0 (43.8% complete)   lr: 0.001242   
2020-02-12 09:19:14,786 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 7/9   Jobs: 2   Epoch: 1.12/2.0 (56.2% complete)   lr: 0.000931   
2020-02-12 09:19:25,984 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 8/9   Jobs: 2   Epoch: 1.38/2.0 (68.8% complete)   lr: 0.000698   
2020-02-12 09:19:37,273 [steps/nnet3/train_dnn.py:355 - train - INFO ] Iter: 9/9   Jobs: 2   Epoch: 1.62/2.0 (81.2% complete)   lr: 0.000340   
2020-02-12 09:19:48,516 [steps/nnet3/train_dnn.py:401 - train - INFO ] Doing final combination to produce final.mdl
2020-02-12 09:19:48,516 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining {6, 7, 8, 9, 10} models.
2020-02-12 09:19:54,132 [steps/nnet3/train_dnn.py:410 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2020-02-12 09:20:34,656 [steps/nnet3/train_dnn.py:421 - train - INFO ] Re-adjusting priors based on computed posteriors
2020-02-12 09:20:35,019 [steps/nnet3/train_dnn.py:431 - train - INFO ] Cleaning up the experiment directory exp/nnet3_vp/tdnn
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/nnet3_vp/tdnn/egs
exp/nnet3_vp/tdnn: num-iters=10 nj=1..2 num-params=11.6M dim=40+100->1408 combine=-0.39->-0.39 (over 1) loglike:train/valid[5,9,combined]=(-0.94,-0.44,-0.38/-1.77,-1.80,-1.81) accuracy:train/valid[5,9,combined]=(0.722,0.871,0.891/0.55,0.58,0.58)
steps/nnet3/decode.sh --nj 11 --cmd run.pl --online-ivector-dir exp/nnet3_vp/ivectors_test exp/tri3b/graph data/test_hires exp/nnet3_vp/tdnn/decode_test_hires
steps/nnet3/decode.sh --nj 9 --cmd run.pl --online-ivector-dir exp/nnet3_vp/ivectors_dev exp/tri3b/graph data/dev_hires exp/nnet3_vp/tdnn/decode_dev_hires
steps/nnet3/decode.sh: feature type is raw
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/tri3b/graph exp/nnet3_vp/tdnn/decode_dev_hires
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_vp/tdnn/decode_dev_hires/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,41) and mean=18.6
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_vp/tdnn/decode_dev_hires/log/analyze_lattice_depth_stats.log
score best paths
exp/nnet3_vp/tdnn/decode_dev_hires/wer_10
%WER 23.91 [ 1819 / 7609, 392 ins, 233 del, 1194 sub ]
%SER 57.95 [ 612 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_11
%WER 23.03 [ 1752 / 7609, 367 ins, 247 del, 1138 sub ]
%SER 56.63 [ 598 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_12
%WER 22.14 [ 1685 / 7609, 330 ins, 263 del, 1092 sub ]
%SER 55.49 [ 586 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_13
%WER 21.17 [ 1611 / 7609, 294 ins, 275 del, 1042 sub ]
%SER 54.45 [ 575 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_14
%WER 20.66 [ 1572 / 7609, 278 ins, 296 del, 998 sub ]
%SER 53.60 [ 566 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_15
%WER 20.19 [ 1536 / 7609, 259 ins, 310 del, 967 sub ]
%SER 53.12 [ 561 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_16
%WER 20.00 [ 1522 / 7609, 249 ins, 331 del, 942 sub ]
%SER 52.84 [ 558 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_17
%WER 19.86 [ 1511 / 7609, 238 ins, 348 del, 925 sub ]
%SER 52.56 [ 555 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_7
%WER 29.19 [ 2221 / 7609, 565 ins, 194 del, 1462 sub ]
%SER 64.58 [ 682 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_8
%WER 26.99 [ 2054 / 7609, 492 ins, 218 del, 1344 sub ]
%SER 61.55 [ 650 / 1056 ]
exp/nnet3_vp/tdnn/decode_dev_hires/wer_9
%WER 25.04 [ 1905 / 7609, 434 ins, 227 del, 1244 sub ]
%SER 59.56 [ 629 / 1056 ]
score confidence and timing with sclite
Decoding done.
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/tri3b/graph exp/nnet3_vp/tdnn/decode_test_hires
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_vp/tdnn/decode_test_hires/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,6,60) and mean=26.9
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_vp/tdnn/decode_test_hires/log/analyze_lattice_depth_stats.log
score best paths
exp/nnet3_vp/tdnn/decode_test_hires/wer_10
%WER 28.48 [ 2297 / 8064, 262 ins, 442 del, 1593 sub ]
%SER 71.15 [ 646 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_11
%WER 27.57 [ 2223 / 8064, 233 ins, 472 del, 1518 sub ]
%SER 70.15 [ 637 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_12
%WER 26.97 [ 2175 / 8064, 214 ins, 507 del, 1454 sub ]
%SER 69.60 [ 632 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_13
%WER 26.46 [ 2134 / 8064, 198 ins, 543 del, 1393 sub ]
%SER 68.94 [ 626 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_14
%WER 26.03 [ 2099 / 8064, 175 ins, 588 del, 1336 sub ]
%SER 68.06 [ 618 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_15
%WER 25.82 [ 2082 / 8064, 164 ins, 608 del, 1310 sub ]
%SER 67.51 [ 613 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_16
%WER 25.52 [ 2058 / 8064, 154 ins, 635 del, 1269 sub ]
%SER 66.74 [ 606 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_17
%WER 25.24 [ 2035 / 8064, 139 ins, 651 del, 1245 sub ]
%SER 66.30 [ 602 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_7
%WER 33.00 [ 2661 / 8064, 416 ins, 362 del, 1883 sub ]
%SER 75.22 [ 683 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_8
%WER 31.10 [ 2508 / 8064, 354 ins, 395 del, 1759 sub ]
%SER 72.69 [ 660 / 908 ]
exp/nnet3_vp/tdnn/decode_test_hires/wer_9
%WER 29.77 [ 2401 / 8064, 305 ins, 433 del, 1663 sub ]
%SER 71.59 [ 650 / 908 ]
score confidence and timing with sclite
Decoding done.
