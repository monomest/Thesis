Tue Jul 13 14:04:57 AEST 2021
Using custom data configuration default-37316b26926a9f32
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                              0%|          | 0/300 [00:00<?, ?ex/s]100%|██████████| 300/300 [00:00<00:00, 8157.16ex/s]
  0%|          | 0/100 [00:00<?, ?ex/s]100%|██████████| 100/100 [00:00<00:00, 8395.32ex/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 385.19ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 649.98ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage.py
Started: 13/07/2021 14:04:58

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210713
datasetdict_id: short
use_checkpoint: False
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210713.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210713
--> pretrained_mod: facebook/wav2vec2-base-960h
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...
Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.
--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                               okay
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                               good
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  well i don't know but i think have humans have...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  if you decrease the washers the force of the m...
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  um i forget its name but i think it starts wit...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {' ': 0, 'N': 1, 'H': 2, 'U': 3, 'M': 4, 'A': 5, 'Z': 6, 'I': 7, 'Q': 8, "'": 9, 'L': 10, 'C': 11, 'E': 12, 'W': 13, 'P': 14, 'J': 15, 'Y': 16, 'F': 17, 'D': 18, 'K': 19, 'G': 20, 'V': 21, 'O': 22, 'R': 23, 'S': 24, 'B': 25, 'X': 26, 'T': 27}
--> Vocab len: 30 
 {'N': 1, 'H': 2, 'U': 3, 'M': 4, 'A': 5, 'Z': 6, 'I': 7, 'Q': 8, "'": 9, 'L': 10, 'C': 11, 'E': 12, 'W': 13, 'P': 14, 'J': 15, 'Y': 16, 'F': 17, 'D': 18, 'K': 19, 'G': 20, 'V': 21, 'O': 22, 'R': 23, 'S': 24, 'B': 25, 'X': 26, 'T': 27, '|': 0, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210713.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


 #0:   0%|          | 0/75 [00:00<?, ?ex/s]
 #1:   0%|          | 0/75 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/75 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/75 [00:00<?, ?ex/s][A[A[A

 #2:   1%|▏         | 1/75 [00:00<00:21,  3.37ex/s][A[A


 #3:   1%|▏         | 1/75 [00:00<00:29,  2.54ex/s][A[A[A

 #2:   3%|▎         | 2/75 [00:00<00:19,  3.74ex/s][A[A #0:   1%|▏         | 1/75 [00:00<00:38,  1.90ex/s]


 #3:   3%|▎         | 2/75 [00:00<00:22,  3.23ex/s][A[A[A
 #1:   1%|▏         | 1/75 [00:00<00:38,  1.90ex/s][A
 #1:   3%|▎         | 2/75 [00:00<00:29,  2.47ex/s][A

 #2:   4%|▍         | 3/75 [00:00<00:16,  4.24ex/s][A[A


 #3:   7%|▋         | 5/75 [00:00<00:16,  4.27ex/s][A[A[A #0:   5%|▌         | 4/75 [00:00<00:27,  2.59ex/s]

 #2:   5%|▌         | 4/75 [00:00<00:13,  5.10ex/s][A[A
 #1:   5%|▌         | 4/75 [00:00<00:21,  3.31ex/s][A


 #3:  15%|█▍        | 11/75 [00:00<00:10,  5.92ex/s][A[A[A #0:   9%|▉         | 7/75 [00:00<00:19,  3.56ex/s]
 #1:  17%|█▋        | 13/75 [00:00<00:13,  4.64ex/s][A #0:  13%|█▎        | 10/75 [00:00<00:13,  4.77ex/s]
 #1:  29%|██▉       | 22/75 [00:00<00:08,  6.48ex/s][A #0:  19%|█▊        | 14/75 [00:01<00:09,  6.42ex/s]

 #2:  13%|█▎        | 10/75 [00:01<00:09,  6.54ex/s][A[A
 #1:  52%|█████▏    | 39/75 [00:01<00:03,  9.09ex/s][A


 #3:  23%|██▎       | 17/75 [00:01<00:07,  7.39ex/s][A[A[A #0:  29%|██▉       | 22/75 [00:01<00:06,  8.78ex/s]

 #2:  15%|█▍        | 11/75 [00:01<00:09,  6.91ex/s][A[A
 #1:  63%|██████▎   | 47/75 [00:01<00:02, 12.33ex/s][A


 #3:  27%|██▋       | 20/75 [00:01<00:05,  9.32ex/s][A[A[A

 #2:  17%|█▋        | 13/75 [00:01<00:07,  8.01ex/s][A[A #0:  35%|███▍      | 26/75 [00:01<00:04, 10.73ex/s]


 #3:  37%|███▋      | 28/75 [00:01<00:03, 12.58ex/s][A[A[A #0:  39%|███▊      | 29/75 [00:01<00:03, 12.94ex/s]
 #1:  73%|███████▎  | 55/75 [00:01<00:01, 14.90ex/s][A


 #3:  45%|████▌     | 34/75 [00:01<00:02, 16.36ex/s][A[A[A

 #2:  25%|██▌       | 19/75 [00:01<00:05, 10.50ex/s][A[A #0:  48%|████▊     | 36/75 [00:01<00:02, 16.74ex/s]


 #3:  52%|█████▏    | 39/75 [00:01<00:01, 19.61ex/s][A[A[A

 #2:  37%|███▋      | 28/75 [00:01<00:03, 14.16ex/s][A[A #0:  56%|█████▌    | 42/75 [00:01<00:01, 21.22ex/s]
 #1:  83%|████████▎ | 62/75 [00:01<00:00, 17.49ex/s][A

 #2:  55%|█████▍    | 41/75 [00:01<00:01, 19.32ex/s][A[A


 #3:  64%|██████▍   | 48/75 [00:01<00:01, 25.26ex/s][A[A[A #0:  64%|██████▍   | 48/75 [00:01<00:01, 25.90ex/s]

 #2:  72%|███████▏  | 54/75 [00:01<00:00, 25.91ex/s][A[A


 #3:  79%|███████▊  | 59/75 [00:01<00:00, 32.78ex/s][A[A[A

 #2:  85%|████████▌ | 64/75 [00:01<00:00, 32.98ex/s][A[A


 #3:  89%|████████▉ | 67/75 [00:01<00:00, 38.84ex/s][A[A[A
 #1:  91%|█████████ | 68/75 [00:01<00:00, 19.06ex/s][A #3: 100%|██████████| 75/75 [00:01<00:00, 37.62ex/s] #0:  76%|███████▌  | 57/75 [00:02<00:00, 30.39ex/s] #1: 100%|██████████| 75/75 [00:02<00:00, 36.77ex/s]

 #2:  97%|█████████▋| 73/75 [00:02<00:00, 39.55ex/s][A[A #2: 100%|██████████| 75/75 [00:02<00:00, 35.69ex/s] #0:  83%|████████▎ | 62/75 [00:02<00:00, 26.57ex/s] #0:  88%|████████▊ | 66/75 [00:02<00:00, 28.26ex/s] #0:  96%|█████████▌| 72/75 [00:02<00:00, 27.33ex/s] #0: 100%|██████████| 75/75 [00:02<00:00, 28.47ex/s]


 #0:   0%|          | 0/25 [00:00<?, ?ex/s]
 #1:   0%|          | 0/25 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/25 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/25 [00:00<?, ?ex/s][A[A[A
 #1:   4%|▍         | 1/25 [00:00<00:04,  5.96ex/s][A


 #3:   4%|▍         | 1/25 [00:00<00:04,  5.98ex/s][A[A[A

 #2:   4%|▍         | 1/25 [00:00<00:05,  4.14ex/s][A[A #0:   4%|▍         | 1/25 [00:00<00:07,  3.32ex/s]
 #1:  12%|█▏        | 3/25 [00:00<00:03,  6.99ex/s][A


 #3:   8%|▊         | 2/25 [00:00<00:04,  5.66ex/s][A[A[A

 #2:  12%|█▏        | 3/25 [00:00<00:04,  5.16ex/s][A[A
 #1:  36%|███▌      | 9/25 [00:00<00:01,  9.51ex/s][A #0:   8%|▊         | 2/25 [00:00<00:05,  3.90ex/s]


 #3:  16%|█▌        | 4/25 [00:00<00:03,  6.87ex/s][A[A[A

 #2:  28%|██▊       | 7/25 [00:00<00:02,  6.92ex/s][A[A
 #1:  72%|███████▏  | 18/25 [00:00<00:00, 12.99ex/s][A #0:  16%|█▌        | 4/25 [00:00<00:04,  5.11ex/s] #1: 100%|██████████| 25/25 [00:00<00:00, 42.19ex/s]


 #3:  52%|█████▏    | 13/25 [00:00<00:01,  9.49ex/s][A[A[A

 #2:  64%|██████▍   | 16/25 [00:00<00:00,  9.56ex/s][A[A #0:  36%|███▌      | 9/25 [00:00<00:02,  6.95ex/s]


 #3:  92%|█████████▏| 23/25 [00:00<00:00, 13.02ex/s][A[A[A #3: 100%|██████████| 25/25 [00:00<00:00, 34.52ex/s]

 #2: 100%|██████████| 25/25 [00:00<00:00, 12.92ex/s][A[A #2: 100%|██████████| 25/25 [00:00<00:00, 33.22ex/s] #0:  60%|██████    | 15/25 [00:00<00:01,  9.44ex/s] #0: 100%|██████████| 25/25 [00:00<00:00, 12.88ex/s] #0: 100%|██████████| 25/25 [00:00<00:00, 27.93ex/s]



--> Verifying data with a random sample...
Target text: MMM HMM YEAH
Input array shape: (30112,)
Sampling rate: 16000
 #0:   0%|          | 0/10 [00:00<?, ?ba/s]
 #1:   0%|          | 0/10 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/10 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  10%|█         | 1/10 [00:00<00:02,  3.11ba/s][A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  10%|█         | 1/10 [00:00<00:02,  3.19ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  10%|█         | 1/10 [00:00<00:03,  2.89ba/s][A
 #1:  20%|██        | 2/10 [00:00<00:02,  3.04ba/s][A


 #3:  20%|██        | 2/10 [00:00<00:02,  3.16ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  10%|█         | 1/10 [00:00<00:06,  1.36ba/s]

 #2:  20%|██        | 2/10 [00:00<00:02,  2.88ba/s][A[A
 #1:  30%|███       | 3/10 [00:00<00:02,  3.49ba/s][A

 #2:  30%|███       | 3/10 [00:01<00:02,  2.81ba/s][A[A
 #1:  40%|████      | 4/10 [00:01<00:01,  3.33ba/s][A


 #3:  30%|███       | 3/10 [00:01<00:02,  2.67ba/s][A[A[A #0:  20%|██        | 2/10 [00:01<00:05,  1.49ba/s]
 #1:  50%|█████     | 5/10 [00:01<00:01,  3.69ba/s][A

 #2:  40%|████      | 4/10 [00:01<00:02,  2.85ba/s][A[A
 #1:  60%|██████    | 6/10 [00:01<00:00,  4.29ba/s][A


 #3:  40%|████      | 4/10 [00:01<00:02,  2.35ba/s][A[A[A
 #1:  70%|███████   | 7/10 [00:01<00:00,  4.06ba/s][A #0:  30%|███       | 3/10 [00:01<00:04,  1.58ba/s]

 #2:  50%|█████     | 5/10 [00:01<00:01,  2.76ba/s][A[A
 #1:  80%|████████  | 8/10 [00:02<00:00,  4.01ba/s][A

 #2:  60%|██████    | 6/10 [00:02<00:01,  3.22ba/s][A[A


 #3:  50%|█████     | 5/10 [00:02<00:02,  2.36ba/s][A[A[A #0:  40%|████      | 4/10 [00:02<00:03,  1.75ba/s]
 #1:  90%|█████████ | 9/10 [00:02<00:00,  3.81ba/s][A #1: 100%|██████████| 10/10 [00:02<00:00,  4.18ba/s]

 #2:  70%|███████   | 7/10 [00:02<00:01,  2.99ba/s][A[A


 #3:  60%|██████    | 6/10 [00:02<00:01,  2.56ba/s][A[A[A #0:  50%|█████     | 5/10 [00:02<00:02,  1.94ba/s]


 #3:  70%|███████   | 7/10 [00:02<00:01,  2.51ba/s][A[A[A

 #2:  80%|████████  | 8/10 [00:02<00:00,  2.68ba/s][A[A #0:  60%|██████    | 6/10 [00:03<00:01,  2.09ba/s]

 #2:  90%|█████████ | 9/10 [00:03<00:00,  2.93ba/s][A[A

 #2: 100%|██████████| 10/10 [00:03<00:00,  3.50ba/s][A[A #2: 100%|██████████| 10/10 [00:03<00:00,  3.03ba/s]


 #3:  80%|████████  | 8/10 [00:03<00:00,  2.41ba/s][A[A[A #0:  70%|███████   | 7/10 [00:03<00:01,  2.06ba/s]


 #3:  90%|█████████ | 9/10 [00:03<00:00,  2.40ba/s][A[A[A


 #3: 100%|██████████| 10/10 [00:03<00:00,  3.05ba/s][A[A[A #3: 100%|██████████| 10/10 [00:03<00:00,  2.61ba/s] #0:  80%|████████  | 8/10 [00:03<00:00,  2.13ba/s] #0:  90%|█████████ | 9/10 [00:04<00:00,  2.69ba/s] #0: 100%|██████████| 10/10 [00:04<00:00,  2.42ba/s]


 #0:   0%|          | 0/4 [00:00<?, ?ba/s]

 #2:   0%|          | 0/4 [00:00<?, ?ba/s][A[A
 #1:   0%|          | 0/4 [00:00<?, ?ba/s][A


 #3:   0%|          | 0/4 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  25%|██▌       | 1/4 [00:00<00:00,  3.33ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  25%|██▌       | 1/4 [00:00<00:01,  2.39ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  25%|██▌       | 1/4 [00:00<00:01,  1.92ba/s][A


 #3:  50%|█████     | 2/4 [00:00<00:00,  2.81ba/s][A[A[A #0:  50%|█████     | 2/4 [00:00<00:00,  3.20ba/s]
 #1:  50%|█████     | 2/4 [00:00<00:00,  2.29ba/s][A


 #3:  75%|███████▌  | 3/4 [00:00<00:00,  3.44ba/s][A[A[A #3: 100%|██████████| 4/4 [00:00<00:00,  5.05ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  25%|██▌       | 1/4 [00:00<00:02,  1.18ba/s][A[A #0:  75%|███████▌  | 3/4 [00:00<00:00,  3.31ba/s]
 #1:  75%|███████▌  | 3/4 [00:01<00:00,  2.47ba/s][A #0: 100%|██████████| 4/4 [00:01<00:00,  3.76ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  3.63ba/s] #1: 100%|██████████| 4/4 [00:01<00:00,  3.44ba/s]

 #2:  50%|█████     | 2/4 [00:01<00:01,  1.44ba/s][A[A

 #2:  75%|███████▌  | 3/4 [00:01<00:00,  1.55ba/s][A[A #2: 100%|██████████| 4/4 [00:01<00:00,  2.24ba/s]



Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 40
  Gradient Accumulation steps = 1
  Total optimization steps = 160
  0%|          | 0/160 [00:00<?, ?it/s]--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

Traceback (most recent call last):
  File "run_finetune_kids_after-outage.py", line 501, in <module>
    trainer.train()
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1269, in train
    tr_loss += self.training_step(model, inputs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1760, in training_step
    loss = self.compute_loss(model, inputs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1794, in compute_loss
    outputs = model(**inputs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 167, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 177, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/_utils.py", line 429, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1472, in forward
    return_dict=return_dict,
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1062, in forward
    hidden_states, extract_features = self.feature_projection(extract_features)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 346, in forward
    hidden_states = self.projection(norm_hidden_states)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`

  0%|          | 0/160 [00:07<?, ?it/s]