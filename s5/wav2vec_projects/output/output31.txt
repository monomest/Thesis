Using custom data configuration default-37316b26926a9f32
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                              0%|          | 0/300 [00:00<?, ?ex/s]100%|██████████| 300/300 [00:00<00:00, 9831.48ex/s]
  0%|          | 0/100 [00:00<?, ?ex/s]100%|██████████| 100/100 [00:00<00:00, 10413.90ex/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 496.31ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 884.31ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_checkpoint_test.py
Started: 11/07/2021 20:55:11

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/20210711-3
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210711-3.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3
--> pretrained_mod: facebook/wav2vec2-base-960h
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-20210711
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /srv/scratch/chacmod/.cache/huggingface/datasets/20210711-3/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...
Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/20210711-3/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.
--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                      it's a magnet
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  so they're not dangerous to touch
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                               good
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                      no because um
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                    yeah i think so
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'F': 0, 'O': 1, 'Q': 2, 'H': 3, 'L': 4, 'S': 5, 'W': 6, 'I': 7, 'U': 8, 'V': 9, 'N': 10, 'A': 11, 'E': 12, "'": 13, 'Y': 14, 'K': 15, 'R': 16, 'G': 17, 'Z': 18, 'X': 19, 'C': 20, ' ': 21, 'D': 22, 'B': 23, 'T': 24, 'P': 25, 'J': 26, 'M': 27}
--> Vocab len: 30 
 {'F': 0, 'O': 1, 'Q': 2, 'H': 3, 'L': 4, 'S': 5, 'W': 6, 'I': 7, 'U': 8, 'V': 9, 'N': 10, 'A': 11, 'E': 12, "'": 13, 'Y': 14, 'K': 15, 'R': 16, 'G': 17, 'Z': 18, 'X': 19, 'C': 20, 'D': 22, 'B': 23, 'T': 24, 'P': 25, 'J': 26, 'M': 27, '|': 21, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210711-3.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


 #0:   0%|          | 0/75 [00:00<?, ?ex/s]
 #1:   0%|          | 0/75 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/75 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/75 [00:00<?, ?ex/s][A[A[A
 #1:  28%|██▊       | 21/75 [00:00<00:00, 205.01ex/s][A #0:   5%|▌         | 4/75 [00:00<00:02, 35.21ex/s]

 #2:  23%|██▎       | 17/75 [00:00<00:00, 164.93ex/s][A[A


 #3:  21%|██▏       | 16/75 [00:00<00:00, 150.22ex/s][A[A[A #0:  19%|█▊        | 14/75 [00:00<00:01, 43.67ex/s]
 #1:  61%|██████▏   | 46/75 [00:00<00:00, 213.64ex/s][A

 #2:  45%|████▌     | 34/75 [00:00<00:00, 166.17ex/s][A[A


 #3:  37%|███▋      | 28/75 [00:00<00:00, 137.11ex/s][A[A[A #0:  40%|████      | 30/75 [00:00<00:00, 55.64ex/s]
 #1:  93%|█████████▎| 70/75 [00:00<00:00, 219.77ex/s][A

 #2:  75%|███████▍  | 56/75 [00:00<00:00, 179.19ex/s][A[A #1: 100%|██████████| 75/75 [00:00<00:00, 232.53ex/s]


 #3:  56%|█████▌    | 42/75 [00:00<00:00, 137.53ex/s][A[A[A #2: 100%|██████████| 75/75 [00:00<00:00, 194.09ex/s] #0:  67%|██████▋   | 50/75 [00:00<00:00, 70.90ex/s]


 #3:  83%|████████▎ | 62/75 [00:00<00:00, 151.65ex/s][A[A[A #3: 100%|██████████| 75/75 [00:00<00:00, 158.32ex/s] #0:  99%|█████████▊| 74/75 [00:00<00:00, 89.31ex/s] #0: 100%|██████████| 75/75 [00:00<00:00, 133.62ex/s]



 #0:   0%|          | 0/25 [00:00<?, ?ex/s]
 #1:   0%|          | 0/25 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/25 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/25 [00:00<?, ?ex/s][A[A[A #0:  72%|███████▏  | 18/25 [00:00<00:00, 177.58ex/s]
 #1:  76%|███████▌  | 19/25 [00:00<00:00, 188.70ex/s][A

 #2:  40%|████      | 10/25 [00:00<00:00, 99.41ex/s][A[A


 #3:  88%|████████▊ | 22/25 [00:00<00:00, 198.72ex/s][A[A[A #1: 100%|██████████| 25/25 [00:00<00:00, 188.70ex/s] #3: 100%|██████████| 25/25 [00:00<00:00, 212.53ex/s] #0: 100%|██████████| 25/25 [00:00<00:00, 172.35ex/s]

 #2:  88%|████████▊ | 22/25 [00:00<00:00, 102.20ex/s][A[A #2: 100%|██████████| 25/25 [00:00<00:00, 103.37ex/s]



--> Verifying data with a random sample...
Target text: IT'S GETTING COLDER
Input array shape: (20400,)
Sampling rate: 16000
 #0:   0%|          | 0/10 [00:00<?, ?ba/s]
 #1:   0%|          | 0/10 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/10 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  10%|█         | 1/10 [00:00<00:02,  4.02ba/s][A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  10%|█         | 1/10 [00:00<00:02,  3.71ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  10%|█         | 1/10 [00:00<00:02,  3.48ba/s][A[A[A
 #1:  20%|██        | 2/10 [00:00<00:02,  3.62ba/s][A


 #3:  20%|██        | 2/10 [00:00<00:02,  3.47ba/s][A[A[A

 #2:  20%|██        | 2/10 [00:00<00:02,  3.50ba/s][A[A
 #1:  30%|███       | 3/10 [00:00<00:01,  3.99ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  10%|█         | 1/10 [00:00<00:07,  1.22ba/s]


 #3:  30%|███       | 3/10 [00:01<00:02,  2.90ba/s][A[A[A
 #1:  40%|████      | 4/10 [00:01<00:01,  3.60ba/s][A

 #2:  30%|███       | 3/10 [00:01<00:02,  2.92ba/s][A[A
 #1:  50%|█████     | 5/10 [00:01<00:01,  3.89ba/s][A #0:  20%|██        | 2/10 [00:01<00:05,  1.34ba/s]
 #1:  60%|██████    | 6/10 [00:01<00:00,  4.52ba/s][A

 #2:  40%|████      | 4/10 [00:01<00:02,  2.90ba/s][A[A


 #3:  40%|████      | 4/10 [00:01<00:02,  2.55ba/s][A[A[A
 #1:  70%|███████   | 7/10 [00:01<00:00,  4.19ba/s][A

 #2:  50%|█████     | 5/10 [00:01<00:01,  2.77ba/s][A[A


 #3:  50%|█████     | 5/10 [00:01<00:01,  2.55ba/s][A[A[A
 #1:  80%|████████  | 8/10 [00:01<00:00,  4.05ba/s][A #0:  30%|███       | 3/10 [00:02<00:04,  1.41ba/s]

 #2:  60%|██████    | 6/10 [00:02<00:01,  3.23ba/s][A[A


 #3:  60%|██████    | 6/10 [00:02<00:01,  2.76ba/s][A[A[A
 #1:  90%|█████████ | 9/10 [00:02<00:00,  3.87ba/s][A #1: 100%|██████████| 10/10 [00:02<00:00,  4.29ba/s]

 #2:  70%|███████   | 7/10 [00:02<00:01,  2.96ba/s][A[A #0:  40%|████      | 4/10 [00:02<00:03,  1.56ba/s]


 #3:  70%|███████   | 7/10 [00:02<00:01,  2.71ba/s][A[A[A #0:  50%|█████     | 5/10 [00:02<00:02,  1.75ba/s]

 #2:  80%|████████  | 8/10 [00:02<00:00,  2.64ba/s][A[A


 #3:  80%|████████  | 8/10 [00:03<00:00,  2.61ba/s][A[A[A

 #2:  90%|█████████ | 9/10 [00:03<00:00,  2.92ba/s][A[A #0:  60%|██████    | 6/10 [00:03<00:02,  1.92ba/s]

 #2: 100%|██████████| 10/10 [00:03<00:00,  3.50ba/s][A[A #2: 100%|██████████| 10/10 [00:03<00:00,  3.01ba/s]


 #3:  90%|█████████ | 9/10 [00:03<00:00,  2.58ba/s][A[A[A


 #3: 100%|██████████| 10/10 [00:03<00:00,  3.26ba/s][A[A[A #3: 100%|██████████| 10/10 [00:03<00:00,  2.81ba/s] #0:  70%|███████   | 7/10 [00:03<00:01,  1.90ba/s] #0:  80%|████████  | 8/10 [00:04<00:01,  1.99ba/s] #0:  90%|█████████ | 9/10 [00:04<00:00,  2.50ba/s] #0: 100%|██████████| 10/10 [00:04<00:00,  2.22ba/s]


 #1:   0%|          | 0/4 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/4 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/4 [00:00<?, ?ba/s][A[A[A #0:   0%|          | 0/4 [00:00<?, ?ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  25%|██▌       | 1/4 [00:00<00:00,  3.96ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  25%|██▌       | 1/4 [00:00<00:00,  3.06ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  25%|██▌       | 1/4 [00:00<00:01,  2.33ba/s][A[A[A
 #1:  50%|█████     | 2/4 [00:00<00:00,  3.47ba/s][A #0:  50%|█████     | 2/4 [00:00<00:00,  3.65ba/s]


 #3:  50%|█████     | 2/4 [00:00<00:00,  2.82ba/s][A[A[A


 #3:  75%|███████▌  | 3/4 [00:00<00:00,  3.49ba/s][A[A[A #3: 100%|██████████| 4/4 [00:00<00:00,  5.26ba/s]
 #1:  75%|███████▌  | 3/4 [00:00<00:00,  3.42ba/s][A #0:  75%|███████▌  | 3/4 [00:00<00:00,  3.64ba/s] #1: 100%|██████████| 4/4 [00:00<00:00,  4.49ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/ba][A[A #0: 100%|██████████| 4/4 [00:01<00:00,  4.07ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  3.88ba/s]

 #2:  50%|█████     | 2/4 [00:01<00:01,  1.25ba/s][A[A

 #2:  75%|███████▌  | 3/4 [00:01<00:00,  1.42ba/s][A[A #2: 100%|██████████| 4/4 [00:01<00:00,  2.14ba/s]



Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 300
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:04<21:42,  4.36s/it]  1%|          | 2/300 [00:05<16:34,  3.34s/it]  1%|          | 3/300 [00:05<12:20,  2.49s/it]  1%|▏         | 4/300 [00:08<12:53,  2.61s/it]  2%|▏         | 5/300 [00:09<10:36,  2.16s/it]  2%|▏         | 6/300 [00:10<08:09,  1.67s/it]  2%|▏         | 7/300 [00:14<11:35,  2.37s/it]  3%|▎         | 8/300 [00:15<09:46,  2.01s/it]  3%|▎         | 9/300 [00:16<07:36,  1.57s/it]  3%|▎         | 10/300 [00:20<11:53,  2.46s/it]  4%|▎         | 11/300 [00:21<10:00,  2.08s/it]  4%|▍         | 12/300 [00:22<07:35,  1.58s/it]  4%|▍         | 13/300 [00:25<09:49,  2.05s/it]  5%|▍         | 14/300 [00:26<08:21,  1.75s/it]  5%|▌         | 15/300 [00:26<06:38,  1.40s/it]  5%|▌         | 16/300 [00:31<11:03,  2.34s/it]  6%|▌         | 17/300 [00:32<09:38,  2.05s/it]  6%|▌         | 18/300 [00:33<07:28,  1.59s/it]  6%|▋         | 19/300 [00:37<11:17,  2.41s/it]  7%|▋         | 20/300 [00:38<09:10,  1.97s/it]  7%|▋         | 21/300 [00:39<06:58,  1.50s/it]  7%|▋         | 22/300 [00:42<09:19,  2.01s/it]  8%|▊         | 23/300 [00:43<07:59,  1.73s/it]  8%|▊         | 24/300 [00:43<06:17,  1.37s/it]  8%|▊         | 25/300 [00:47<08:49,  1.92s/it]  9%|▊         | 26/300 [00:48<07:43,  1.69s/it]  9%|▉         | 27/300 [00:48<06:08,  1.35s/it]  9%|▉         | 28/300 [00:51<08:30,  1.88s/it] 10%|▉         | 29/300 [00:53<07:25,  1.64s/it] 10%|█         | 30/300 [00:53<05:58,  1.33s/it] 10%|█         | 31/300 [00:57<09:53,  2.21s/it] 11%|█         | 32/300 [00:58<08:23,  1.88s/it] 11%|█         | 33/300 [00:59<06:34,  1.48s/it] 11%|█▏        | 34/300 [01:02<08:47,  1.98s/it] 12%|█▏        | 35/300 [01:03<07:46,  1.76s/it] 12%|█▏        | 36/300 [01:04<05:59,  1.36s/it] 12%|█▏        | 37/300 [01:08<09:22,  2.14s/it] 13%|█▎        | 38/300 [01:09<08:08,  1.86s/it] 13%|█▎        | 39/300 [01:10<06:26,  1.48s/it] 13%|█▎        | 40/300 [01:12<07:27,  1.72s/it] 14%|█▎        | 41/300 [01:13<06:25,  1.49s/it] 14%|█▍        | 42/300 [01:13<05:03,  1.18s/it] 14%|█▍        | 43/300 [01:18<08:58,  2.10s/it] 15%|█▍        | 44/300 [01:18<07:26,  1.75s/it] 15%|█▌        | 45/300 [01:19<05:52,  1.38s/it] 15%|█▌        | 46/300 [01:24<10:10,  2.40s/it] 16%|█▌        | 47/300 [01:25<08:28,  2.01s/it] 16%|█▌        | 48/300 [01:25<06:27,  1.54s/it] 16%|█▋        | 49/300 [01:28<08:06,  1.94s/it] 17%|█▋        | 50/300 [01:29<07:11,  1.73s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-50
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-50/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-50/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-50/preprocessor_config.json
 17%|█▋        | 51/300 [01:32<08:30,  2.05s/it] 17%|█▋        | 52/300 [01:36<11:05,  2.68s/it] 18%|█▊        | 53/300 [01:38<09:10,  2.23s/it] 18%|█▊        | 54/300 [01:38<07:03,  1.72s/it] 18%|█▊        | 55/300 [01:41<08:37,  2.11s/it] 19%|█▊        | 56/300 [01:42<07:09,  1.76s/it] 19%|█▉        | 57/300 [01:42<05:27,  1.35s/it] 19%|█▉        | 58/300 [01:47<09:02,  2.24s/it] 20%|█▉        | 59/300 [01:48<07:15,  1.81s/it] 20%|██        | 60/300 [01:48<05:45,  1.44s/it] 20%|██        | 61/300 [01:53<09:18,  2.34s/it] 21%|██        | 62/300 [01:54<07:44,  1.95s/it] 21%|██        | 63/300 [01:54<06:04,  1.54s/it] 21%|██▏       | 64/300 [01:57<07:46,  1.98s/it] 22%|██▏       | 65/300 [01:59<07:05,  1.81s/it] 22%|██▏       | 66/300 [01:59<05:33,  1.43s/it] 22%|██▏       | 67/300 [02:03<08:51,  2.28s/it] 23%|██▎       | 68/300 [02:04<07:05,  1.83s/it] 23%|██▎       | 69/300 [02:05<05:35,  1.45s/it] 23%|██▎       | 70/300 [02:09<09:02,  2.36s/it] 24%|██▎       | 71/300 [02:10<07:21,  1.93s/it] 24%|██▍       | 72/300 [02:11<05:37,  1.48s/it] 24%|██▍       | 73/300 [02:13<06:55,  1.83s/it] 25%|██▍       | 74/300 [02:14<05:57,  1.58s/it] 25%|██▌       | 75/300 [02:15<04:45,  1.27s/it] 25%|██▌       | 76/300 [02:19<08:12,  2.20s/it] 26%|██▌       | 77/300 [02:20<06:56,  1.87s/it] 26%|██▌       | 78/300 [02:21<05:29,  1.48s/it] 26%|██▋       | 79/300 [02:24<07:15,  1.97s/it] 27%|██▋       | 80/300 [02:25<06:15,  1.71s/it] 27%|██▋       | 81/300 [02:25<04:51,  1.33s/it] 27%|██▋       | 82/300 [02:30<07:45,  2.14s/it] 28%|██▊       | 83/300 [02:31<06:38,  1.84s/it] 28%|██▊       | 84/300 [02:31<05:08,  1.43s/it] 28%|██▊       | 85/300 [02:34<06:35,  1.84s/it] 29%|██▊       | 86/300 [02:35<05:27,  1.53s/it] 29%|██▉       | 87/300 [02:35<04:23,  1.24s/it] 29%|██▉       | 88/300 [02:38<05:54,  1.67s/it] 30%|██▉       | 89/300 [02:39<05:00,  1.42s/it] 30%|███       | 90/300 [02:39<04:03,  1.16s/it] 30%|███       | 91/300 [02:44<07:19,  2.10s/it] 31%|███       | 92/300 [02:45<06:12,  1.79s/it] 31%|███       | 93/300 [02:45<04:53,  1.42s/it] 31%|███▏      | 94/300 [02:48<06:25,  1.87s/it] 32%|███▏      | 95/300 [02:50<05:49,  1.71s/it] 32%|███▏      | 96/300 [02:50<04:34,  1.35s/it] 32%|███▏      | 97/300 [02:54<07:41,  2.27s/it] 33%|███▎      | 98/300 [02:55<06:15,  1.86s/it] 33%|███▎      | 99/300 [02:56<04:46,  1.43s/it] 33%|███▎      | 100/300 [02:59<06:14,  1.87s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-100
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-100/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-100/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-100/preprocessor_config.json
 34%|███▎      | 101/300 [03:02<07:21,  2.22s/it] 34%|███▍      | 102/300 [03:02<05:37,  1.71s/it] 34%|███▍      | 103/300 [03:06<08:00,  2.44s/it] 35%|███▍      | 104/300 [03:07<06:34,  2.01s/it] 35%|███▌      | 105/300 [03:08<04:57,  1.53s/it] 35%|███▌      | 106/300 [03:12<07:40,  2.37s/it] 36%|███▌      | 107/300 [03:13<06:21,  1.98s/it] 36%|███▌      | 108/300 [03:14<04:46,  1.49s/it] 36%|███▋      | 109/300 [03:16<05:40,  1.78s/it] 37%|███▋      | 110/300 [03:17<04:45,  1.50s/it] 37%|███▋      | 111/300 [03:17<03:51,  1.22s/it] 37%|███▋      | 112/300 [03:21<05:35,  1.78s/it] 38%|███▊      | 113/300 [03:22<04:54,  1.58s/it] 38%|███▊      | 114/300 [03:22<03:55,  1.26s/it] 38%|███▊      | 115/300 [03:26<06:44,  2.19s/it] 39%|███▊      | 116/300 [03:28<05:38,  1.84s/it] 39%|███▉      | 117/300 [03:28<04:24,  1.45s/it] 39%|███▉      | 118/300 [03:31<05:44,  1.89s/it] 40%|███▉      | 119/300 [03:32<04:48,  1.59s/it] 40%|████      | 120/300 [03:32<03:51,  1.28s/it] 40%|████      | 121/300 [03:37<06:39,  2.23s/it] 41%|████      | 122/300 [03:38<05:40,  1.91s/it] 41%|████      | 123/300 [03:39<04:25,  1.50s/it] 41%|████▏     | 124/300 [03:41<05:19,  1.82s/it] 42%|████▏     | 125/300 [03:42<04:36,  1.58s/it] 42%|████▏     | 126/300 [03:43<03:41,  1.27s/it] 42%|████▏     | 127/300 [03:47<06:06,  2.12s/it] 43%|████▎     | 128/300 [03:48<05:12,  1.81s/it] 43%|████▎     | 129/300 [03:48<04:01,  1.41s/it] 43%|████▎     | 130/300 [03:51<05:17,  1.87s/it] 44%|████▎     | 131/300 [03:52<04:23,  1.56s/it] 44%|████▍     | 132/300 [03:53<03:25,  1.23s/it] 44%|████▍     | 133/300 [03:56<04:48,  1.73s/it] 45%|████▍     | 134/300 [03:56<04:08,  1.50s/it] 45%|████▌     | 135/300 [03:57<03:15,  1.18s/it] 45%|████▌     | 136/300 [04:01<05:33,  2.03s/it] 46%|████▌     | 137/300 [04:02<04:39,  1.71s/it] 46%|████▌     | 138/300 [04:02<03:40,  1.36s/it] 46%|████▋     | 139/300 [04:06<05:13,  1.95s/it] 47%|████▋     | 140/300 [04:07<04:26,  1.67s/it] 47%|████▋     | 141/300 [04:07<03:25,  1.29s/it] 47%|████▋     | 142/300 [04:11<05:42,  2.17s/it] 48%|████▊     | 143/300 [04:13<04:58,  1.90s/it] 48%|████▊     | 144/300 [04:13<03:54,  1.50s/it] 48%|████▊     | 145/300 [04:16<04:58,  1.93s/it] 49%|████▊     | 146/300 [04:17<04:08,  1.61s/it] 49%|████▉     | 147/300 [04:18<03:17,  1.29s/it] 49%|████▉     | 148/300 [04:22<05:41,  2.24s/it] 50%|████▉     | 149/300 [04:23<04:50,  1.92s/it] 50%|█████     | 150/300 [04:24<03:43,  1.49s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-150
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-150/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-150/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-150/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-50] due to args.save_total_limit
 50%|█████     | 151/300 [04:31<08:02,  3.24s/it] 51%|█████     | 152/300 [04:32<06:17,  2.55s/it] 51%|█████     | 153/300 [04:32<04:45,  1.94s/it] 51%|█████▏    | 154/300 [04:36<05:31,  2.27s/it] 52%|█████▏    | 155/300 [04:37<04:39,  1.93s/it] 52%|█████▏    | 156/300 [04:37<03:34,  1.49s/it] 52%|█████▏    | 157/300 [04:42<05:40,  2.38s/it] 53%|█████▎    | 158/300 [04:43<04:36,  1.95s/it] 53%|█████▎    | 159/300 [04:43<03:35,  1.53s/it] 53%|█████▎    | 160/300 [04:46<04:43,  2.03s/it] 54%|█████▎    | 161/300 [04:47<03:55,  1.69s/it] 54%|█████▍    | 162/300 [04:48<03:00,  1.31s/it] 54%|█████▍    | 163/300 [04:50<03:58,  1.74s/it] 55%|█████▍    | 164/300 [04:51<03:29,  1.54s/it] 55%|█████▌    | 165/300 [04:52<02:44,  1.22s/it] 55%|█████▌    | 166/300 [04:56<04:48,  2.16s/it] 56%|█████▌    | 167/300 [04:57<03:59,  1.80s/it] 56%|█████▌    | 168/300 [04:58<02:59,  1.36s/it] 56%|█████▋    | 169/300 [05:02<04:54,  2.25s/it] 57%|█████▋    | 170/300 [05:03<04:07,  1.90s/it] 57%|█████▋    | 171/300 [05:03<03:10,  1.48s/it] 57%|█████▋    | 172/300 [05:07<04:11,  1.97s/it] 58%|█████▊    | 173/300 [05:07<03:30,  1.66s/it] 58%|█████▊    | 174/300 [05:08<02:48,  1.34s/it] 58%|█████▊    | 175/300 [05:11<03:52,  1.86s/it] 59%|█████▊    | 176/300 [05:12<03:19,  1.61s/it] 59%|█████▉    | 177/300 [05:13<02:32,  1.24s/it] 59%|█████▉    | 178/300 [05:15<03:06,  1.53s/it] 60%|█████▉    | 179/300 [05:16<02:49,  1.40s/it] 60%|██████    | 180/300 [05:16<02:19,  1.16s/it] 60%|██████    | 181/300 [05:21<04:13,  2.13s/it] 61%|██████    | 182/300 [05:22<03:24,  1.74s/it] 61%|██████    | 183/300 [05:22<02:42,  1.39s/it] 61%|██████▏   | 184/300 [05:27<04:26,  2.30s/it] 62%|██████▏   | 185/300 [05:28<03:44,  1.96s/it] 62%|██████▏   | 186/300 [05:28<02:52,  1.52s/it] 62%|██████▏   | 187/300 [05:31<03:43,  1.98s/it] 63%|██████▎   | 188/300 [05:32<03:10,  1.70s/it] 63%|██████▎   | 189/300 [05:33<02:28,  1.33s/it] 63%|██████▎   | 190/300 [05:36<03:13,  1.76s/it] 64%|██████▎   | 191/300 [05:37<02:44,  1.51s/it] 64%|██████▍   | 192/300 [05:37<02:09,  1.20s/it] 64%|██████▍   | 193/300 [05:40<03:04,  1.73s/it] 65%|██████▍   | 194/300 [05:41<02:45,  1.56s/it] 65%|██████▌   | 195/300 [05:42<02:12,  1.27s/it] 65%|██████▌   | 196/300 [05:46<03:30,  2.02s/it] 66%|██████▌   | 197/300 [05:46<02:55,  1.70s/it] 66%|██████▌   | 198/300 [05:47<02:16,  1.33s/it] 66%|██████▋   | 199/300 [05:51<03:49,  2.28s/it] 67%|██████▋   | 200/300 [05:52<03:07,  1.87s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-200
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-200/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-200/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-200/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-100] due to args.save_total_limit
 67%|██████▋   | 201/300 [05:56<03:42,  2.25s/it] 67%|██████▋   | 202/300 [05:58<03:58,  2.43s/it] 68%|██████▊   | 203/300 [05:59<03:13,  1.99s/it] 68%|██████▊   | 204/300 [06:00<02:24,  1.51s/it] 68%|██████▊   | 205/300 [06:04<03:47,  2.40s/it] 69%|██████▊   | 206/300 [06:05<03:10,  2.03s/it] 69%|██████▉   | 207/300 [06:06<02:28,  1.59s/it] 69%|██████▉   | 208/300 [06:09<02:55,  1.91s/it] 70%|██████▉   | 209/300 [06:10<02:33,  1.69s/it] 70%|███████   | 210/300 [06:10<01:58,  1.32s/it] 70%|███████   | 211/300 [06:15<03:17,  2.22s/it] 71%|███████   | 212/300 [06:15<02:41,  1.84s/it] 71%|███████   | 213/300 [06:16<02:06,  1.46s/it] 71%|███████▏  | 214/300 [06:19<02:45,  1.93s/it] 72%|███████▏  | 215/300 [06:20<02:24,  1.70s/it] 72%|███████▏  | 216/300 [06:21<01:52,  1.34s/it] 72%|███████▏  | 217/300 [06:25<03:08,  2.27s/it] 73%|███████▎  | 218/300 [06:26<02:32,  1.86s/it] 73%|███████▎  | 219/300 [06:27<01:57,  1.45s/it] 73%|███████▎  | 220/300 [06:30<02:34,  1.93s/it] 74%|███████▎  | 221/300 [06:31<02:10,  1.65s/it] 74%|███████▍  | 222/300 [06:31<01:42,  1.32s/it] 74%|███████▍  | 223/300 [06:34<02:20,  1.82s/it] 75%|███████▍  | 224/300 [06:35<01:57,  1.55s/it] 75%|███████▌  | 225/300 [06:35<01:29,  1.20s/it] 75%|███████▌  | 226/300 [06:40<02:33,  2.07s/it] 76%|███████▌  | 227/300 [06:41<02:09,  1.77s/it] 76%|███████▌  | 228/300 [06:41<01:39,  1.38s/it] 76%|███████▋  | 229/300 [06:44<02:13,  1.87s/it] 77%|███████▋  | 230/300 [06:45<01:50,  1.58s/it] 77%|███████▋  | 231/300 [06:45<01:24,  1.23s/it] 77%|███████▋  | 232/300 [06:50<02:25,  2.13s/it] 78%|███████▊  | 233/300 [06:51<02:03,  1.85s/it] 78%|███████▊  | 234/300 [06:51<01:33,  1.42s/it] 78%|███████▊  | 235/300 [06:54<01:50,  1.70s/it] 79%|███████▊  | 236/300 [06:54<01:31,  1.43s/it] 79%|███████▉  | 237/300 [06:55<01:13,  1.17s/it] 79%|███████▉  | 238/300 [06:59<02:14,  2.17s/it] 80%|███████▉  | 239/300 [07:01<01:52,  1.84s/it] 80%|████████  | 240/300 [07:01<01:25,  1.42s/it] 80%|████████  | 241/300 [07:05<02:14,  2.28s/it] 81%|████████  | 242/300 [07:06<01:51,  1.93s/it] 81%|████████  | 243/300 [07:07<01:24,  1.49s/it] 81%|████████▏ | 244/300 [07:10<01:51,  1.99s/it] 82%|████████▏ | 245/300 [07:11<01:32,  1.69s/it] 82%|████████▏ | 246/300 [07:12<01:13,  1.37s/it] 82%|████████▏ | 247/300 [07:16<02:03,  2.34s/it] 83%|████████▎ | 248/300 [07:17<01:41,  1.96s/it] 83%|████████▎ | 249/300 [07:18<01:17,  1.53s/it] 83%|████████▎ | 250/300 [07:21<01:33,  1.88s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-250
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-250/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-250/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-250/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-150] due to args.save_total_limit
 84%|████████▎ | 251/300 [07:24<01:56,  2.37s/it] 84%|████████▍ | 252/300 [07:25<01:27,  1.82s/it] 84%|████████▍ | 253/300 [07:29<02:02,  2.61s/it] 85%|████████▍ | 254/300 [07:30<01:39,  2.16s/it] 85%|████████▌ | 255/300 [07:31<01:15,  1.67s/it] 85%|████████▌ | 256/300 [07:35<01:47,  2.44s/it] 86%|████████▌ | 257/300 [07:36<01:28,  2.07s/it] 86%|████████▌ | 258/300 [07:37<01:07,  1.62s/it] 86%|████████▋ | 259/300 [07:39<01:17,  1.89s/it] 87%|████████▋ | 260/300 [07:40<01:04,  1.61s/it] 87%|████████▋ | 261/300 [07:41<00:50,  1.29s/it] 87%|████████▋ | 262/300 [07:45<01:22,  2.17s/it] 88%|████████▊ | 263/300 [07:46<01:07,  1.82s/it] 88%|████████▊ | 264/300 [07:46<00:51,  1.44s/it] 88%|████████▊ | 265/300 [07:50<01:07,  1.93s/it] 89%|████████▊ | 266/300 [07:50<00:54,  1.60s/it] 89%|████████▉ | 267/300 [07:51<00:42,  1.29s/it] 89%|████████▉ | 268/300 [07:56<01:12,  2.27s/it] 90%|████████▉ | 269/300 [07:57<00:59,  1.91s/it] 90%|█████████ | 270/300 [07:57<00:43,  1.45s/it] 90%|█████████ | 271/300 [08:01<01:08,  2.35s/it] 91%|█████████ | 272/300 [08:02<00:54,  1.94s/it] 91%|█████████ | 273/300 [08:03<00:40,  1.49s/it] 91%|█████████▏| 274/300 [08:07<01:01,  2.35s/it] 92%|█████████▏| 275/300 [08:08<00:47,  1.89s/it] 92%|█████████▏| 276/300 [08:09<00:35,  1.49s/it] 92%|█████████▏| 277/300 [08:11<00:43,  1.90s/it] 93%|█████████▎| 278/300 [08:12<00:35,  1.63s/it] 93%|█████████▎| 279/300 [08:13<00:27,  1.30s/it] 93%|█████████▎| 280/300 [08:17<00:43,  2.18s/it] 94%|█████████▎| 281/300 [08:18<00:34,  1.83s/it] 94%|█████████▍| 282/300 [08:19<00:25,  1.42s/it] 94%|█████████▍| 283/300 [08:22<00:31,  1.86s/it] 95%|█████████▍| 284/300 [08:23<00:26,  1.65s/it] 95%|█████████▌| 285/300 [08:23<00:19,  1.32s/it] 95%|█████████▌| 286/300 [08:28<00:31,  2.26s/it] 96%|█████████▌| 287/300 [08:29<00:25,  1.96s/it] 96%|█████████▌| 288/300 [08:29<00:18,  1.50s/it] 96%|█████████▋| 289/300 [08:33<00:21,  2.00s/it] 97%|█████████▋| 290/300 [08:34<00:17,  1.74s/it] 97%|█████████▋| 291/300 [08:34<00:12,  1.35s/it] 97%|█████████▋| 292/300 [08:37<00:15,  1.91s/it] 98%|█████████▊| 293/300 [08:39<00:11,  1.70s/it] 98%|█████████▊| 294/300 [08:39<00:07,  1.33s/it] 98%|█████████▊| 295/300 [08:43<00:10,  2.19s/it] 99%|█████████▊| 296/300 [08:44<00:07,  1.76s/it] 99%|█████████▉| 297/300 [08:44<00:04,  1.39s/it] 99%|█████████▉| 298/300 [08:49<00:04,  2.34s/it]100%|█████████▉| 299/300 [08:50<00:01,  1.95s/it]100%|██████████| 300/300 [08:51<00:00,  1.54s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-300
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-300/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-300/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-300/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/checkpoint-200] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 300/300 [08:54<00:00,  1.54s/it]100%|██████████| 300/300 [08:54<00:00,  1.78s/it]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/pytorch_model.bin
loading feature extractor configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/preprocessor_config.json
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/added_tokens.json. We won't load it.
Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/tokenizer.json. We won't load it.
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/vocab.json
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/tokenizer_config.json
loading file None
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/special_tokens_map.json
loading file None
loading configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/config.json
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3/pytorch_model.bin
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711-3.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:10,  9.87ex/s]  5%|▌         | 5/100 [00:00<00:07, 12.52ex/s]  8%|▊         | 8/100 [00:00<00:06, 15.15ex/s] 11%|█         | 11/100 [00:00<00:05, 15.30ex/s] 14%|█▍        | 14/100 [00:00<00:05, 16.73ex/s] 16%|█▌        | 16/100 [00:00<00:04, 17.36ex/s] 19%|█▉        | 19/100 [00:00<00:04, 17.89ex/s] 22%|██▏       | 22/100 [00:01<00:03, 20.04ex/s] 25%|██▌       | 25/100 [00:01<00:04, 15.35ex/s] 28%|██▊       | 28/100 [00:01<00:04, 17.15ex/s] 31%|███       | 31/100 [00:01<00:03, 19.16ex/s] 34%|███▍      | 34/100 [00:01<00:03, 18.62ex/s] 37%|███▋      | 37/100 [00:01<00:03, 19.63ex/s] 40%|████      | 40/100 [00:01<00:02, 20.64ex/s] 43%|████▎     | 43/100 [00:02<00:02, 19.81ex/s] 47%|████▋     | 47/100 [00:02<00:02, 22.26ex/s] 50%|█████     | 50/100 [00:02<00:02, 18.15ex/s] 53%|█████▎    | 53/100 [00:02<00:02, 16.03ex/s] 55%|█████▌    | 55/100 [00:03<00:03, 12.47ex/s] 58%|█████▊    | 58/100 [00:03<00:03, 11.08ex/s] 61%|██████    | 61/100 [00:03<00:02, 13.42ex/s] 63%|██████▎   | 63/100 [00:03<00:02, 13.70ex/s] 65%|██████▌   | 65/100 [00:03<00:02, 14.25ex/s] 68%|██████▊   | 68/100 [00:03<00:02, 13.57ex/s] 71%|███████   | 71/100 [00:04<00:01, 15.35ex/s] 73%|███████▎  | 73/100 [00:04<00:02, 11.55ex/s] 75%|███████▌  | 75/100 [00:04<00:02, 12.36ex/s] 77%|███████▋  | 77/100 [00:04<00:01, 11.63ex/s] 80%|████████  | 80/100 [00:04<00:01, 14.17ex/s] 85%|████████▌ | 85/100 [00:05<00:00, 15.43ex/s] 89%|████████▉ | 89/100 [00:05<00:00, 18.61ex/s] 95%|█████████▌| 95/100 [00:05<00:00, 23.24ex/s] 99%|█████████▉| 99/100 [00:05<00:00, 23.58ex/s]100%|██████████| 100/100 [00:05<00:00, 18.21ex/s]
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.57ex/s]  5%|▌         | 5/100 [00:00<00:09,  9.89ex/s]  8%|▊         | 8/100 [00:00<00:07, 12.37ex/s] 11%|█         | 11/100 [00:00<00:06, 13.24ex/s] 14%|█▍        | 14/100 [00:00<00:05, 15.01ex/s] 16%|█▌        | 16/100 [00:00<00:05, 16.05ex/s] 19%|█▉        | 19/100 [00:00<00:04, 16.87ex/s] 22%|██▏       | 22/100 [00:01<00:04, 19.22ex/s] 25%|██▌       | 25/100 [00:01<00:04, 15.03ex/s] 27%|██▋       | 27/100 [00:01<00:05, 14.08ex/s] 31%|███       | 31/100 [00:01<00:04, 16.25ex/s] 33%|███▎      | 33/100 [00:01<00:04, 15.33ex/s] 36%|███▌      | 36/100 [00:01<00:03, 17.05ex/s] 39%|███▉      | 39/100 [00:02<00:03, 18.90ex/s] 42%|████▏     | 42/100 [00:02<00:02, 19.87ex/s] 45%|████▌     | 45/100 [00:02<00:02, 21.93ex/s] 48%|████▊     | 48/100 [00:02<00:02, 18.80ex/s] 51%|█████     | 51/100 [00:02<00:02, 17.47ex/s] 53%|█████▎    | 53/100 [00:02<00:02, 16.41ex/s] 55%|█████▌    | 55/100 [00:03<00:03, 12.71ex/s] 58%|█████▊    | 58/100 [00:03<00:03, 11.35ex/s] 61%|██████    | 61/100 [00:03<00:02, 13.75ex/s] 63%|██████▎   | 63/100 [00:03<00:02, 14.03ex/s] 65%|██████▌   | 65/100 [00:03<00:02, 14.40ex/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.77ex/s] 71%|███████   | 71/100 [00:04<00:01, 15.62ex/s] 73%|███████▎  | 73/100 [00:04<00:02, 11.71ex/s] 75%|███████▌  | 75/100 [00:04<00:01, 12.63ex/s] 77%|███████▋  | 77/100 [00:04<00:01, 11.81ex/s] 80%|████████  | 80/100 [00:04<00:01, 14.36ex/s] 85%|████████▌ | 85/100 [00:05<00:00, 16.53ex/s] 88%|████████▊ | 88/100 [00:05<00:00, 18.25ex/s] 93%|█████████▎| 93/100 [00:05<00:00, 22.23ex/s] 97%|█████████▋| 97/100 [00:05<00:00, 22.89ex/s]100%|██████████| 100/100 [00:05<00:00, 18.11ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-20210711
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 534.2029, 'train_samples_per_second': 11.232, 'train_steps_per_second': 0.562, 'train_loss': 0.9749342854817709, 'epoch': 20.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.270
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YAH WE WE DON'T REALLY DO WITH ANYTHING ELSE B...
2                                               YEAH                                                YEA
3                                               YEAH                                               YEAH
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO YET WE PULL IT UP UP AND THEN WE PUSH IT DO...
5                                       THAT SLIPPED                                            THATWIP
6                                        UH HUH YEAH                                                IAM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...  YEA NO IT WAS A MILLER LEAT NO A HUNDRED MILL ...
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASURE MENT YEAHYEA...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE BECAUSE WE WANTED TO...
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> E A A H H <pad> | <pad> W <pad> <pad> E <pad> <pad> | | W <pad> R R <pad> O <pad> <pad> T <pad> E | | | <pad> O U R R <pad> <pad> | | <pad> N <pad> <pad> U M <pad> <pad> B <pad> E R R <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O U <pad> <pad> <pad> T T <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y <pad> <pad> <pad> <pad> <pad> E A A A H <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

--> Getting baseline test results...
Baseline Test WER: 0.318
--> Showing some baseline prediction errors...
                                         target_text                                           pred_str
0                                               YEAH                                             YES NO
1                                               YEAH                                                YES
2                                          WAIT WHAT                                          WAIT WHAT
3                                                YES                                                YES
4  MMM WHEN YOU LIKE HAVE SOME WATER YOU WANNA KN...  WHEN YOU LIKE HAVE SOME WATER YOU WANT TO KNOW...
5  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...
6                                               YEAH                                           MONSIEUR
7                         FOR WAIT UM YEAH BASICALLY                              OF WHICH HUM AR BASIC
8                          I HAVEN'T GOT TO THAT YET                          I HAVEN'T GOT TO THAT YET
9                                                YUP                                                 IF
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 11/07/2021 21:05:27
