Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-47024f6103ac1df2.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-c5b890c5844b797c.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 126.29ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 535.60ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 15/07/2021 15:26:24

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210715-1
datasetdict_id: short
use_checkpoint: True
checkpoint: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715-1.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1
--> pretrained_mod: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  we've been learning about magnets and electricity
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...        well they were sometimes different and well
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                               yeah
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                         skin cells can dry and die
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                                 no
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'R': 0, 'G': 1, 'K': 2, 'W': 3, 'Z': 4, 'S': 5, 'L': 6, 'U': 7, 'Y': 8, 'D': 9, 'T': 10, 'V': 11, "'": 12, ' ': 13, 'P': 14, 'J': 15, 'A': 16, 'M': 17, 'C': 18, 'N': 19, 'H': 20, 'E': 21, 'Q': 22, 'F': 23, 'B': 24, 'X': 25, 'O': 26, 'I': 27}
--> Vocab len: 30 
 {'R': 0, 'G': 1, 'K': 2, 'W': 3, 'Z': 4, 'S': 5, 'L': 6, 'U': 7, 'Y': 8, 'D': 9, 'T': 10, 'V': 11, "'": 12, 'P': 14, 'J': 15, 'A': 16, 'M': 17, 'C': 18, 'N': 19, 'H': 20, 'E': 21, 'Q': 22, 'F': 23, 'B': 24, 'X': 25, 'O': 26, 'I': 27, '|': 13, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715-1.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-b84fec576315d285.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-32482b156ab05203.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-042d4e13c7759f68.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6a15623a8b20aca3.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-897b02773dc1977b.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-78f0e24bd254b7b9.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-5fa7421341e241aa.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-45eb95a440a8bd16.arrow
--> Verifying data with a random sample...
Target text: YES
Input array shape: (9280,)
Sampling rate: 16000
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-fc19af87df56e3a0.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-1286bcb1181e8d45.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-452d3ba8d89d8f9e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dfcc468b38ce6b24.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-88e1fc4038eed18e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-8ede2ed0863dad80.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-badef0cc11e36328.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d2a32ed91d56d325.arrow
Using amp fp16 backend
Loading model from /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250).
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 300
  Continuing training from checkpoint, will skip to saved global_step
  Continuing training from epoch 16
  Continuing training from global step 250
  Will skip the first 16 epochs then the first 10 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.
  0%|          | 0/10 [00:00<?, ?it/s]Skipping the first batches:   0%|          | 0/10 [00:00<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s][ASkipping the first batches:  10%|█         | 1/10 [00:31<04:45, 31.73s/it]Skipping the first batches:  20%|██        | 2/10 [00:32<02:59, 22.43s/it]Skipping the first batches:  30%|███       | 3/10 [00:32<01:50, 15.77s/it]Skipping the first batches:  40%|████      | 4/10 [00:34<01:09, 11.56s/it]Skipping the first batches:  50%|█████     | 5/10 [00:34<00:41,  8.26s/it]Skipping the first batches:  60%|██████    | 6/10 [00:35<00:23,  5.84s/it]Skipping the first batches:  70%|███████   | 7/10 [00:37<00:13,  4.67s/it]Skipping the first batches:  80%|████████  | 8/10 [00:37<00:06,  3.46s/it]Skipping the first batches:  90%|█████████ | 9/10 [00:38<00:02,  2.52s/it]Skipping the first batches: 100%|██████████| 10/10 [00:39<00:00,  2.19s/it]Skipping the first batches: 100%|██████████| 10/10 [00:40<00:00,  4.01s/it]

 84%|████████▎ | 251/300 [00:40<00:07,  6.16it/s][A
 84%|████████▍ | 252/300 [00:41<00:13,  3.48it/s][A
 84%|████████▍ | 253/300 [00:46<01:16,  1.64s/it][A
 85%|████████▍ | 254/300 [00:47<01:09,  1.50s/it][A
 85%|████████▌ | 255/300 [00:47<00:54,  1.22s/it][A
 85%|████████▌ | 256/300 [00:52<01:38,  2.25s/it][A
 86%|████████▌ | 257/300 [00:53<01:24,  1.97s/it][A
 86%|████████▌ | 258/300 [00:54<01:05,  1.55s/it][A
 86%|████████▋ | 259/300 [00:57<01:17,  1.88s/it][A
 87%|████████▋ | 260/300 [00:58<01:04,  1.62s/it][A
 87%|████████▋ | 261/300 [00:58<00:50,  1.30s/it][A
 87%|████████▋ | 262/300 [01:03<01:26,  2.27s/it][A
 88%|████████▊ | 263/300 [01:04<01:10,  1.91s/it][A
 88%|████████▊ | 264/300 [01:04<00:54,  1.52s/it][A
 88%|████████▊ | 265/300 [01:08<01:13,  2.09s/it][A
 89%|████████▊ | 266/300 [01:09<00:58,  1.73s/it][A
 89%|████████▉ | 267/300 [01:09<00:45,  1.38s/it][A
 89%|████████▉ | 268/300 [01:14<01:18,  2.46s/it][A
 90%|████████▉ | 269/300 [01:15<01:03,  2.04s/it][A
 90%|█████████ | 270/300 [01:16<00:46,  1.54s/it][A
 90%|█████████ | 271/300 [01:20<01:10,  2.44s/it][A
 91%|█████████ | 272/300 [01:21<00:56,  2.01s/it][A
 91%|█████████ | 273/300 [01:22<00:41,  1.53s/it][A
 91%|█████████▏| 274/300 [01:26<01:01,  2.38s/it][A
 92%|█████████▏| 275/300 [01:27<00:47,  1.92s/it][A
 92%|█████████▏| 276/300 [01:27<00:35,  1.49s/it][A
 92%|█████████▏| 277/300 [01:30<00:44,  1.94s/it][A
 93%|█████████▎| 278/300 [01:31<00:36,  1.67s/it][A
 93%|█████████▎| 279/300 [01:32<00:28,  1.34s/it][A
 93%|█████████▎| 280/300 [01:36<00:45,  2.27s/it][A
 94%|█████████▎| 281/300 [01:37<00:36,  1.92s/it][A
 94%|█████████▍| 282/300 [01:38<00:26,  1.49s/it][A
 94%|█████████▍| 283/300 [01:41<00:34,  2.00s/it][A
 95%|█████████▍| 284/300 [01:42<00:28,  1.77s/it][A
 95%|█████████▌| 285/300 [01:43<00:21,  1.41s/it][A
 95%|█████████▌| 286/300 [01:48<00:33,  2.40s/it][A
 96%|█████████▌| 287/300 [01:49<00:26,  2.08s/it][A
 96%|█████████▌| 288/300 [01:49<00:19,  1.60s/it][A
 96%|█████████▋| 289/300 [01:53<00:23,  2.13s/it][A
 97%|█████████▋| 290/300 [01:54<00:18,  1.84s/it][A
 97%|█████████▋| 291/300 [01:54<00:12,  1.43s/it][A
 97%|█████████▋| 292/300 [01:58<00:16,  2.08s/it][A
 98%|█████████▊| 293/300 [01:59<00:12,  1.79s/it][A
 98%|█████████▊| 294/300 [02:00<00:08,  1.39s/it][A
 98%|█████████▊| 295/300 [02:04<00:11,  2.26s/it][A
 99%|█████████▊| 296/300 [02:05<00:07,  1.82s/it][A
 99%|█████████▉| 297/300 [02:05<00:04,  1.45s/it][A
 99%|█████████▉| 298/300 [02:10<00:04,  2.40s/it][A
100%|█████████▉| 299/300 [02:11<00:02,  2.00s/it][A
100%|██████████| 300/300 [02:12<00:00,  1.59s/it][ASaving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/checkpoint-300
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/checkpoint-300/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/checkpoint-300/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/checkpoint-300/preprocessor_config.json


Training completed. Do not forget to share your model on huggingface.co/models =)



                                                 [A
100%|██████████| 300/300 [02:14<00:00,  1.59s/it][A100%|██████████| 300/300 [02:14<00:00,  2.23it/s]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/pytorch_model.bin
loading feature extractor configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/preprocessor_config.json
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/added_tokens.json. We won't load it.
Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/tokenizer.json. We won't load it.
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/vocab.json
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/tokenizer_config.json
loading file None
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/special_tokens_map.json
loading file None
loading configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/config.json
Model config Wav2Vec2Config {
  "_name_or_path": "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1/pytorch_model.bin
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715-1.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.32ex/s]  5%|▌         | 5/100 [00:00<00:10,  9.31ex/s]  7%|▋         | 7/100 [00:00<00:08, 10.92ex/s] 10%|█         | 10/100 [00:00<00:06, 13.45ex/s] 12%|█▏        | 12/100 [00:00<00:07, 12.54ex/s] 14%|█▍        | 14/100 [00:00<00:06, 12.88ex/s] 16%|█▌        | 16/100 [00:00<00:06, 13.48ex/s] 18%|█▊        | 18/100 [00:01<00:05, 14.42ex/s] 20%|██        | 20/100 [00:01<00:05, 13.63ex/s] 23%|██▎       | 23/100 [00:01<00:04, 15.78ex/s] 25%|██▌       | 25/100 [00:01<00:06, 11.01ex/s] 27%|██▋       | 27/100 [00:01<00:05, 12.28ex/s] 30%|███       | 30/100 [00:01<00:04, 14.43ex/s] 32%|███▏      | 32/100 [00:02<00:04, 15.02ex/s] 34%|███▍      | 34/100 [00:02<00:04, 14.08ex/s] 36%|███▌      | 36/100 [00:02<00:04, 14.51ex/s] 39%|███▉      | 39/100 [00:02<00:03, 15.68ex/s] 42%|████▏     | 42/100 [00:02<00:03, 16.31ex/s] 44%|████▍     | 44/100 [00:02<00:03, 16.93ex/s] 47%|████▋     | 47/100 [00:02<00:02, 18.04ex/s] 49%|████▉     | 49/100 [00:03<00:03, 14.60ex/s] 51%|█████     | 51/100 [00:03<00:03, 12.93ex/s] 53%|█████▎    | 53/100 [00:03<00:03, 12.74ex/s] 55%|█████▌    | 55/100 [00:03<00:04, 10.36ex/s] 58%|█████▊    | 58/100 [00:04<00:04,  9.40ex/s] 61%|██████    | 61/100 [00:04<00:03, 11.27ex/s] 63%|██████▎   | 63/100 [00:04<00:03, 11.43ex/s] 65%|██████▌   | 65/100 [00:04<00:02, 11.95ex/s] 67%|██████▋   | 67/100 [00:04<00:02, 13.14ex/s] 69%|██████▉   | 69/100 [00:04<00:02, 10.78ex/s] 72%|███████▏  | 72/100 [00:05<00:02,  9.64ex/s] 74%|███████▍  | 74/100 [00:05<00:02, 11.11ex/s] 77%|███████▋  | 77/100 [00:05<00:02, 10.70ex/s] 79%|███████▉  | 79/100 [00:05<00:01, 12.19ex/s] 82%|████████▏ | 82/100 [00:05<00:01, 14.82ex/s] 84%|████████▍ | 84/100 [00:06<00:01, 13.70ex/s] 86%|████████▌ | 86/100 [00:06<00:01, 13.58ex/s] 89%|████████▉ | 89/100 [00:06<00:00, 15.61ex/s] 94%|█████████▍| 94/100 [00:06<00:00, 19.24ex/s] 97%|█████████▋| 97/100 [00:06<00:00, 18.73ex/s]100%|██████████| 100/100 [00:06<00:00, 14.68ex/s]
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:11,  9.00ex/s]  5%|▌         | 5/100 [00:00<00:08, 11.20ex/s]  7%|▋         | 7/100 [00:00<00:07, 12.82ex/s] 10%|█         | 10/100 [00:00<00:05, 15.45ex/s] 12%|█▏        | 12/100 [00:00<00:06, 13.93ex/s] 14%|█▍        | 14/100 [00:00<00:06, 13.89ex/s] 16%|█▌        | 16/100 [00:00<00:05, 14.51ex/s] 18%|█▊        | 18/100 [00:01<00:05, 15.26ex/s] 20%|██        | 20/100 [00:01<00:05, 14.34ex/s] 23%|██▎       | 23/100 [00:01<00:04, 16.66ex/s] 25%|██▌       | 25/100 [00:01<00:06, 11.24ex/s] 27%|██▋       | 27/100 [00:01<00:05, 12.68ex/s] 30%|███       | 30/100 [00:01<00:04, 14.90ex/s] 32%|███▏      | 32/100 [00:01<00:04, 15.16ex/s] 34%|███▍      | 34/100 [00:02<00:04, 14.08ex/s] 36%|███▌      | 36/100 [00:02<00:04, 14.61ex/s] 39%|███▉      | 39/100 [00:02<00:03, 15.80ex/s] 42%|████▏     | 42/100 [00:02<00:03, 16.25ex/s] 44%|████▍     | 44/100 [00:02<00:03, 16.92ex/s] 47%|████▋     | 47/100 [00:02<00:02, 18.25ex/s] 49%|████▉     | 49/100 [00:03<00:03, 14.99ex/s] 51%|█████     | 51/100 [00:03<00:03, 13.20ex/s] 53%|█████▎    | 53/100 [00:03<00:03, 12.78ex/s] 55%|█████▌    | 55/100 [00:03<00:04, 10.22ex/s] 58%|█████▊    | 58/100 [00:04<00:04,  9.29ex/s] 61%|██████    | 61/100 [00:04<00:03, 11.08ex/s] 63%|██████▎   | 63/100 [00:04<00:03, 11.38ex/s] 65%|██████▌   | 65/100 [00:04<00:02, 11.97ex/s] 67%|██████▋   | 67/100 [00:04<00:02, 13.23ex/s] 69%|██████▉   | 69/100 [00:04<00:02, 10.79ex/s] 72%|███████▏  | 72/100 [00:05<00:02,  9.75ex/s] 74%|███████▍  | 74/100 [00:05<00:02, 11.16ex/s] 77%|███████▋  | 77/100 [00:05<00:02, 10.85ex/s] 79%|███████▉  | 79/100 [00:05<00:01, 12.32ex/s] 83%|████████▎ | 83/100 [00:05<00:01, 15.08ex/s] 85%|████████▌ | 85/100 [00:06<00:01, 14.33ex/s] 87%|████████▋ | 87/100 [00:06<00:01, 13.00ex/s] 90%|█████████ | 90/100 [00:06<00:00, 15.60ex/s] 95%|█████████▌| 95/100 [00:06<00:00, 19.26ex/s] 98%|█████████▊| 98/100 [00:06<00:00, 18.36ex/s]100%|██████████| 100/100 [00:06<00:00, 14.85ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 134.6538, 'train_samples_per_second': 44.559, 'train_steps_per_second': 2.228, 'train_loss': 0.09436628977457683, 'epoch': 20.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.276
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YEAH WE WE DON'T REALLY DO WITH ANYTHING ELSE ...
2                                               YEAH                                                YEA
3                                               YEAH                                              YEANO
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO YEAH WE PULL IT UP UP AND THEN WE PUSH IT D...
5                                       THAT SLIPPED                                               AWIP
6                                        UH HUH YEAH                                             IMI AM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...  YEAHNO IT WAS A MILLER LEAT NO A HUNDRED MILL ...
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASUREMENTYEAHYEAH ...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE BECAUSE WE WANTED TO...
--> Taking a deeper look...
<pad> <pad> Y <pad> <pad> <pad> <pad> E A A H H <pad> | | <pad> W <pad> <pad> E <pad> <pad> | <pad> W R R R <pad> O <pad> <pad> <pad> T E <pad> | <pad> O <pad> <pad> R E <pad> <pad> | | <pad> N <pad> <pad> U M <pad> <pad> B <pad> E R R <pad> E D <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O U <pad> <pad> <pad> <pad> T T <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y <pad> <pad> <pad> <pad> E A A H H <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

--> Getting baseline test results...
Baseline Test WER: 0.318
--> Showing some baseline prediction errors...
                                         target_text                                           pred_str
0                                               YEAH                                             YES NO
1                                               YEAH                                                YES
2                                          WAIT WHAT                                          WAIT WHAT
3                                                YES                                                YES
4  MMM WHEN YOU LIKE HAVE SOME WATER YOU WANNA KN...  WHEN YOU LIKE HAVE SOME WATER YOU WANT TO KNOW...
5  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...
6                                               YEAH                                           MONSIEUR
7                         FOR WAIT UM YEAH BASICALLY                              OF WHICH HUM AR BASIC
8                          I HAVEN'T GOT TO THAT YET                          I HAVEN'T GOT TO THAT YET
9                                                YUP                                                 IF
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 15/07/2021 15:29:43
