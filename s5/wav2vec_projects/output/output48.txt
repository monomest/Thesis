Wed Jul 14 10:59:10 AEST 2021
Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
  0%|          | 0/300 [00:00<?, ?ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 7998.70ex/s]
  0%|          | 0/100 [00:00<?, ?ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 7579.29ex/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 338.55ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 597.39ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 14/07/2021 10:59:11

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210714
datasetdict_id: short
use_checkpoint: False
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714
--> pretrained_mod: facebook/wav2vec2-base-960h
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  under those brads there's a wire and when the ...
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  um the cup on the right filled with washers is...
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  uhm it shows the first part of the digestive f...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                       i forgot what they're called
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the um some of the things that uh don't have i...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'X': 0, 'H': 1, 'G': 2, 'L': 3, 'E': 4, 'P': 5, 'Y': 6, 'V': 7, 'B': 8, 'F': 9, 'J': 10, 'D': 11, 'R': 12, 'I': 13, 'S': 14, ' ': 15, 'W': 16, 'T': 17, 'O': 18, 'A': 19, 'M': 20, 'K': 21, 'U': 22, 'Z': 23, "'": 24, 'N': 25, 'Q': 26, 'C': 27}
--> Vocab len: 30 
 {'X': 0, 'H': 1, 'G': 2, 'L': 3, 'E': 4, 'P': 5, 'Y': 6, 'V': 7, 'B': 8, 'F': 9, 'J': 10, 'D': 11, 'R': 12, 'I': 13, 'S': 14, 'W': 16, 'T': 17, 'O': 18, 'A': 19, 'M': 20, 'K': 21, 'U': 22, 'Z': 23, "'": 24, 'N': 25, 'Q': 26, 'C': 27, '|': 15, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


 #0:   0%|          | 0/75 [00:00<?, ?ex/s]
 #1:   0%|          | 0/75 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/75 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/75 [00:00<?, ?ex/s][A[A[A

 #2:   1%|â–         | 1/75 [00:00<00:31,  2.33ex/s][A[A
 #1:   1%|â–         | 1/75 [00:00<00:34,  2.15ex/s][A

 #2:   3%|â–Ž         | 2/75 [00:00<00:24,  2.96ex/s][A[A


 #3:   1%|â–         | 1/75 [00:00<00:46,  1.58ex/s][A[A[A #0:   1%|â–         | 1/75 [00:00<00:50,  1.47ex/s]

 #2:   4%|â–         | 3/75 [00:00<00:19,  3.69ex/s][A[A
 #1:   3%|â–Ž         | 2/75 [00:00<00:28,  2.52ex/s][A


 #3:   3%|â–Ž         | 2/75 [00:00<00:34,  2.11ex/s][A[A[A

 #2:   5%|â–Œ         | 4/75 [00:00<00:16,  4.37ex/s][A[A #0:   5%|â–Œ         | 4/75 [00:00<00:34,  2.04ex/s]
 #1:   5%|â–Œ         | 4/75 [00:00<00:21,  3.34ex/s][A


 #3:   9%|â–‰         | 7/75 [00:00<00:23,  2.96ex/s][A[A[A #0:  12%|â–ˆâ–        | 9/75 [00:00<00:23,  2.85ex/s]


 #3:  15%|â–ˆâ–        | 11/75 [00:00<00:15,  4.08ex/s][A[A[A
 #1:   8%|â–Š         | 6/75 [00:00<00:15,  4.42ex/s][A

 #2:  13%|â–ˆâ–Ž        | 10/75 [00:01<00:11,  5.82ex/s][A[A #0:  17%|â–ˆâ–‹        | 13/75 [00:01<00:15,  3.94ex/s]
 #1:  16%|â–ˆâ–Œ        | 12/75 [00:01<00:10,  6.11ex/s][A
 #1:  29%|â–ˆâ–ˆâ–‰       | 22/75 [00:01<00:06,  8.49ex/s][A #0:  21%|â–ˆâ–ˆâ–       | 16/75 [00:01<00:11,  5.27ex/s]

 #2:  16%|â–ˆâ–Œ        | 12/75 [00:01<00:08,  7.07ex/s][A[A
 #1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37/75 [00:01<00:03, 11.85ex/s][A

 #2:  24%|â–ˆâ–ˆâ–       | 18/75 [00:01<00:05,  9.53ex/s][A[A #0:  29%|â–ˆâ–ˆâ–‰       | 22/75 [00:01<00:07,  7.13ex/s]


 #3:  23%|â–ˆâ–ˆâ–Ž       | 17/75 [00:01<00:11,  5.25ex/s][A[A[A
 #1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/75 [00:01<00:01, 16.01ex/s][A

 #2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/75 [00:01<00:03, 12.95ex/s][A[A


 #3:  29%|â–ˆâ–ˆâ–‰       | 22/75 [00:01<00:07,  7.13ex/s][A[A[A #0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/75 [00:01<00:05,  8.93ex/s]
 #1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56/75 [00:01<00:00, 21.31ex/s][A

 #2:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/75 [00:01<00:02, 17.15ex/s][A[A


 #3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/75 [00:01<00:04,  9.76ex/s][A[A[A
 #1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/75 [00:01<00:00, 27.36ex/s][A

 #2:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/75 [00:01<00:01, 22.59ex/s][A[A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:01<00:00, 44.83ex/s] #0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/75 [00:01<00:04,  9.62ex/s]

 #2:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/75 [00:01<00:00, 30.22ex/s][A[A


 #3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/75 [00:01<00:03, 12.30ex/s][A[A[A #0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/75 [00:01<00:03, 12.36ex/s]

 #2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73/75 [00:01<00:00, 39.04ex/s][A[A


 #3:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/75 [00:01<00:01, 16.77ex/s][A[A[A #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:01<00:00, 39.38ex/s] #0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/75 [00:01<00:02, 14.61ex/s]


 #3:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53/75 [00:01<00:01, 20.48ex/s][A[A[A #0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/75 [00:02<00:01, 18.62ex/s]


 #3:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/75 [00:02<00:00, 26.10ex/s][A[A[A #0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51/75 [00:02<00:00, 24.40ex/s]


 #3:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74/75 [00:02<00:00, 34.30ex/s][A[A[A #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:02<00:00, 34.00ex/s] #0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/75 [00:02<00:00, 26.65ex/s] #0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62/75 [00:02<00:00, 18.68ex/s] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:02<00:00, 25.92ex/s]



 #0:   0%|          | 0/25 [00:00<?, ?ex/s]
 #1:   0%|          | 0/25 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/25 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/25 [00:00<?, ?ex/s][A[A[A
 #1:   4%|â–         | 1/25 [00:00<00:03,  7.72ex/s][A

 #2:   4%|â–         | 1/25 [00:00<00:03,  6.07ex/s][A[A #0:   4%|â–         | 1/25 [00:00<00:05,  4.65ex/s]


 #3:   8%|â–Š         | 2/25 [00:00<00:02,  8.45ex/s][A[A[A
 #1:  24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:01,  9.89ex/s][A

 #2:  16%|â–ˆâ–Œ        | 4/25 [00:00<00:02,  7.73ex/s][A[A #0:   8%|â–Š         | 2/25 [00:00<00:04,  5.16ex/s]


 #3:  16%|â–ˆâ–Œ        | 4/25 [00:00<00:02,  9.55ex/s][A[A[A
 #1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:00<00:00, 13.55ex/s][A

 #2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:00<00:01, 10.53ex/s][A[A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 53.57ex/s] #0:  20%|â–ˆâ–ˆ        | 5/25 [00:00<00:03,  6.58ex/s]


 #3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:00<00:00, 12.82ex/s][A[A[A

 #2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:00<00:00, 14.06ex/s][A[A #0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:00<00:01,  8.96ex/s] #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 40.13ex/s] #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 39.31ex/s] #0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:00<00:00, 12.25ex/s] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 31.49ex/s]



--> Verifying data with a random sample...
Target text: CENTIMETERS AND METERS AND FOOT AND STUFF
Input array shape: (82016,)
Sampling rate: 16000
 #0:   0%|          | 0/10 [00:00<?, ?ba/s]
 #1:   0%|          | 0/10 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/10 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  10%|â–ˆ         | 1/10 [00:00<00:02,  3.33ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  10%|â–ˆ         | 1/10 [00:00<00:02,  3.18ba/s][A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  10%|â–ˆ         | 1/10 [00:00<00:02,  3.01ba/s][A

 #2:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.25ba/s][A[A
 #1:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.01ba/s][A


 #3:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.19ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  10%|â–ˆ         | 1/10 [00:00<00:06,  1.34ba/s]
 #1:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:02,  3.42ba/s][A

 #2:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:02,  2.98ba/s][A[A


 #3:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:02,  2.59ba/s][A[A[A
 #1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:01<00:01,  3.21ba/s][A #0:  20%|â–ˆâ–ˆ        | 2/10 [00:01<00:05,  1.45ba/s]

 #2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:01<00:02,  2.89ba/s][A[A
 #1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:01<00:01,  3.51ba/s][A
 #1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:01<00:00,  4.14ba/s][A

 #2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:01<00:01,  2.73ba/s][A[A


 #3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:01<00:02,  2.23ba/s][A[A[A
 #1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:01<00:00,  3.85ba/s][A #0:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:04,  1.51ba/s]

 #2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:01<00:01,  3.15ba/s][A[A
 #1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:02<00:00,  3.80ba/s][A


 #3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  2.23ba/s][A[A[A #0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:02<00:03,  1.65ba/s]

 #2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:02<00:01,  2.86ba/s][A[A
 #1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:02<00:00,  3.64ba/s][A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.96ba/s]


 #3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:02<00:01,  2.41ba/s][A[A[A #0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  1.80ba/s]

 #2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:02<00:00,  2.59ba/s][A[A


 #3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:03<00:01,  2.37ba/s][A[A[A

 #2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:03<00:00,  2.80ba/s][A[A #0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:03<00:02,  1.91ba/s]

 #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  3.36ba/s][A[A #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.99ba/s]


 #3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:03<00:00,  2.24ba/s][A[A[A #0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:03<00:01,  1.90ba/s]


 #3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:03<00:00,  2.27ba/s][A[A[A


 #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.88ba/s][A[A[A #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.45ba/s] #0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:04<00:01,  1.97ba/s] #0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:04<00:00,  2.52ba/s] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.25ba/s]



 #0:   0%|          | 0/4 [00:00<?, ?ba/s]
 #1:   0%|          | 0/4 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/4 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/4 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.77ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.60ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.75ba/s][A[A[A


 #3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.22ba/s][A[A[A #0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.44ba/s]
 #1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.98ba/s][A


 #3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.84ba/s][A[A[A #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.55ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.24ba/s][A[A #0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.43ba/s]
 #1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  2.95ba/s][A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.92ba/s] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.82ba/s] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.63ba/s]

 #2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.50ba/s][A[A

 #2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  1.60ba/s][A[A #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.30ba/s]



Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 40
  Gradient Accumulation steps = 1
  Total optimization steps = 160
  0%|          | 0/160 [00:00<?, ?it/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  1%|          | 1/160 [00:10<28:10, 10.63s/it]  1%|â–         | 2/160 [00:14<22:51,  8.68s/it]  2%|â–         | 3/160 [00:19<19:20,  7.39s/it]  2%|â–Ž         | 4/160 [00:25<18:28,  7.11s/it]  3%|â–Ž         | 5/160 [00:31<17:24,  6.74s/it]  4%|â–         | 6/160 [00:35<15:06,  5.89s/it]  4%|â–         | 7/160 [00:39<13:54,  5.45s/it]  5%|â–Œ         | 8/160 [00:42<11:31,  4.55s/it]  6%|â–Œ         | 9/160 [00:48<12:47,  5.08s/it]  6%|â–‹         | 10/160 [00:54<13:24,  5.36s/it]  7%|â–‹         | 11/160 [01:00<13:51,  5.58s/it]  8%|â–Š         | 12/160 [01:05<12:58,  5.26s/it]  8%|â–Š         | 13/160 [01:08<11:45,  4.80s/it]  9%|â–‰         | 14/160 [01:13<11:35,  4.76s/it]  9%|â–‰         | 15/160 [01:17<11:02,  4.57s/it] 10%|â–ˆ         | 16/160 [01:19<09:12,  3.84s/it] 11%|â–ˆ         | 17/160 [01:26<11:19,  4.75s/it] 11%|â–ˆâ–        | 18/160 [01:30<10:53,  4.60s/it] 12%|â–ˆâ–        | 19/160 [01:35<10:36,  4.51s/it] 12%|â–ˆâ–Ž        | 20/160 [01:41<11:28,  4.92s/it] 13%|â–ˆâ–Ž        | 21/160 [01:45<10:45,  4.64s/it] 14%|â–ˆâ–        | 22/160 [01:48<10:06,  4.40s/it] 14%|â–ˆâ–        | 23/160 [01:55<11:40,  5.12s/it] 15%|â–ˆâ–Œ        | 24/160 [01:58<09:37,  4.25s/it] 16%|â–ˆâ–Œ        | 25/160 [02:04<11:21,  5.05s/it] 16%|â–ˆâ–‹        | 26/160 [02:10<11:46,  5.27s/it] 17%|â–ˆâ–‹        | 27/160 [02:15<11:07,  5.02s/it] 18%|â–ˆâ–Š        | 28/160 [02:20<11:10,  5.08s/it] 18%|â–ˆâ–Š        | 29/160 [02:24<10:42,  4.90s/it] 19%|â–ˆâ–‰        | 30/160 [02:28<09:55,  4.58s/it] 19%|â–ˆâ–‰        | 31/160 [02:35<11:18,  5.26s/it] 20%|â–ˆâ–ˆ        | 32/160 [02:37<09:12,  4.32s/it] 21%|â–ˆâ–ˆ        | 33/160 [02:44<10:43,  5.06s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [02:49<10:37,  5.06s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [02:53<10:03,  4.82s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [02:58<09:37,  4.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [03:04<10:26,  5.09s/it] 24%|â–ˆâ–ˆâ–       | 38/160 [03:10<11:07,  5.47s/it] 24%|â–ˆâ–ˆâ–       | 39/160 [03:14<10:11,  5.06s/it] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [03:16<08:04,  4.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 41/160 [03:22<09:24,  4.74s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [03:27<09:20,  4.75s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [03:32<09:14,  4.74s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [03:38<10:07,  5.24s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [03:42<09:28,  4.95s/it] 29%|â–ˆâ–ˆâ–‰       | 46/160 [03:45<08:17,  4.36s/it] 29%|â–ˆâ–ˆâ–‰       | 47/160 [03:49<07:53,  4.19s/it] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [03:51<06:45,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [03:58<08:33,  4.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [04:02<08:03,  4.40s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/preprocessor_config.json
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [04:09<09:17,  5.12s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [04:16<10:01,  5.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [04:20<09:31,  5.34s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [04:25<08:46,  4.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [04:30<08:53,  5.08s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [04:32<07:31,  4.34s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [04:39<08:45,  5.10s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [04:46<09:38,  5.68s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [04:50<08:20,  4.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [04:54<08:02,  4.82s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [04:59<07:46,  4.71s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [05:05<08:36,  5.27s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [05:10<08:07,  5.03s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 64/160 [05:12<06:38,  4.15s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [05:19<07:51,  4.97s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [05:23<07:19,  4.68s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [05:26<06:50,  4.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [05:33<07:49,  5.10s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [05:39<08:17,  5.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [05:44<07:44,  5.16s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [05:48<07:12,  4.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [05:50<05:48,  3.96s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [05:56<06:41,  4.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [06:00<06:30,  4.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [06:05<06:21,  4.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [06:11<07:10,  5.12s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [06:16<07:03,  5.10s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [06:21<06:41,  4.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [06:27<07:11,  5.33s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [06:29<05:51,  4.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [06:35<06:24,  4.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [06:40<06:15,  4.81s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [06:45<06:11,  4.82s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [06:51<06:27,  5.09s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [06:55<06:11,  4.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [07:00<05:56,  4.81s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [07:03<05:21,  4.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [07:05<04:31,  3.76s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [07:12<05:32,  4.68s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [07:17<05:19,  4.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [07:23<05:57,  5.18s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [07:28<05:40,  5.01s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [07:32<05:22,  4.81s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [07:36<05:04,  4.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [07:40<04:39,  4.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 96/160 [07:41<03:41,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [07:48<04:33,  4.35s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [07:53<04:52,  4.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [08:00<05:13,  5.15s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [08:04<05:01,  5.02s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/preprocessor_config.json
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [08:12<05:45,  5.86s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [08:16<05:08,  5.33s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [08:21<04:48,  5.07s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [08:23<03:54,  4.19s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [08:29<04:29,  4.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [08:33<04:11,  4.66s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [08:39<04:23,  4.97s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [08:44<04:16,  4.94s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [08:50<04:24,  5.19s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [08:54<04:03,  4.86s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [08:58<03:46,  4.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [09:00<03:09,  3.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [09:07<03:37,  4.64s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [09:11<03:29,  4.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [09:16<03:27,  4.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [09:22<03:44,  5.10s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [09:25<03:14,  4.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [09:29<03:07,  4.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [09:34<03:02,  4.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [09:36<02:31,  3.78s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [09:42<02:56,  4.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [09:47<02:53,  4.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [09:50<02:35,  4.20s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [09:55<02:33,  4.25s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [10:01<02:54,  4.99s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [10:05<02:38,  4.65s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [10:09<02:29,  4.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 128/160 [10:13<02:13,  4.16s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [10:19<02:28,  4.79s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [10:24<02:22,  4.74s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [10:27<02:01,  4.18s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [10:33<02:12,  4.75s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [10:36<02:00,  4.46s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [10:40<01:50,  4.26s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [10:46<02:01,  4.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [10:49<01:37,  4.06s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [10:55<01:50,  4.80s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [10:59<01:40,  4.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [11:02<01:24,  4.00s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [11:08<01:34,  4.74s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [11:13<01:29,  4.72s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [11:17<01:21,  4.52s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [11:21<01:14,  4.38s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [11:25<01:05,  4.12s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [11:31<01:12,  4.83s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [11:36<01:06,  4.75s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [11:42<01:06,  5.10s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [11:46<00:59,  4.97s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [11:51<00:53,  4.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [11:58<00:54,  5.44s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50] due to args.save_total_limit
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [12:06<00:56,  6.33s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [12:08<00:40,  5.10s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [12:14<00:37,  5.39s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [12:18<00:29,  5.00s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [12:23<00:24,  4.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [12:28<00:19,  4.79s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [12:32<00:14,  4.74s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [12:38<00:10,  5.06s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [12:42<00:04,  4.79s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [12:46<00:00,  4.44s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [12:46<00:00,  4.44s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [12:46<00:00,  4.79s/it]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/pytorch_model.bin
loading feature extractor configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/preprocessor_config.json
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/added_tokens.json. We won't load it.
Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/tokenizer.json. We won't load it.
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/vocab.json
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/tokenizer_config.json
loading file None
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/special_tokens_map.json
loading file None
loading configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/config.json
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/pytorch_model.bin
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.24ex/s]  5%|â–Œ         | 5/100 [00:00<00:10,  9.46ex/s]  8%|â–Š         | 8/100 [00:00<00:07, 11.87ex/s] 11%|â–ˆ         | 11/100 [00:00<00:07, 12.70ex/s] 14%|â–ˆâ–        | 14/100 [00:00<00:05, 14.44ex/s] 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 15.46ex/s] 19%|â–ˆâ–‰        | 19/100 [00:00<00:04, 16.33ex/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 18.66ex/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:01<00:05, 14.46ex/s] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:01<00:04, 16.24ex/s] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:01<00:03, 18.29ex/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:01<00:03, 17.99ex/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:01<00:03, 19.13ex/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:02<00:02, 20.18ex/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:02<00:02, 19.39ex/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:02<00:02, 21.95ex/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:02<00:02, 17.94ex/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:02<00:02, 15.86ex/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:03<00:03, 12.17ex/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:03<00:03, 10.92ex/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:03<00:02, 13.24ex/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:03<00:02, 13.48ex/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:03<00:02, 14.00ex/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:04<00:02, 13.32ex/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:04<00:01, 15.13ex/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:04<00:02, 11.25ex/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:04<00:02, 12.14ex/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:04<00:02, 11.40ex/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:04<00:01, 13.91ex/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:05<00:00, 15.10ex/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:05<00:00, 18.27ex/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:05<00:00, 22.89ex/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:05<00:00, 23.37ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:05<00:00, 17.80ex/s]
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.59ex/s]  5%|â–Œ         | 5/100 [00:00<00:09,  9.87ex/s]  8%|â–Š         | 8/100 [00:00<00:07, 12.27ex/s] 11%|â–ˆ         | 11/100 [00:00<00:06, 12.97ex/s] 14%|â–ˆâ–        | 14/100 [00:00<00:05, 14.61ex/s] 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 15.57ex/s] 19%|â–ˆâ–‰        | 19/100 [00:00<00:04, 16.29ex/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 18.54ex/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:01<00:05, 14.44ex/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:01<00:04, 15.68ex/s] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:01<00:03, 17.80ex/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:01<00:03, 17.55ex/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:01<00:03, 17.61ex/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:02<00:03, 19.18ex/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:02<00:02, 19.75ex/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:02<00:02, 21.58ex/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:02<00:02, 18.33ex/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:02<00:02, 16.84ex/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:02<00:02, 15.76ex/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:03<00:03, 12.04ex/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:03<00:03, 10.79ex/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:03<00:02, 13.08ex/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:03<00:02, 13.36ex/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:03<00:02, 13.95ex/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:04<00:02, 13.36ex/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:04<00:01, 15.20ex/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:04<00:02, 11.48ex/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:04<00:02, 12.25ex/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:04<00:01, 11.53ex/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:04<00:01, 14.06ex/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:05<00:00, 16.16ex/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:05<00:00, 16.47ex/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [00:05<00:00, 20.42ex/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:05<00:00, 22.04ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:05<00:00, 17.69ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 766.353, 'train_samples_per_second': 7.829, 'train_steps_per_second': 0.209, 'train_loss': 1.5303815841674804, 'epoch': 20.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.270
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YEAR WE WE DON'T REALLY DO T WITH ANYTHING ELS...
2                                               YEAH                                           MONSIEUR
3                                               YEAH                                              YESNO
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO WHEV WE PULL IT UP UP AND THEN WE PUSH IT D...
5                                       THAT SLIPPED                                        HUSHTHATWIP
6                                        UH HUH YEAH                                               I AM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...  YEANO IT WAS A MILLER LEAT NO A HUNDRED MILL L...
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE BECAUSE WE WANDERED ...
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> E E A H H <pad> <pad> | <pad> W <pad> <pad> E <pad> <pad> | <pad> W R R R <pad> O <pad> <pad> <pad> T E <pad> | <pad> O U <pad> R E <pad> | | | <pad> N <pad> U <pad> M <pad> <pad> B <pad> E R R <pad> <pad> <pad> | | D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O U <pad> <pad> <pad> <pad> T T <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y <pad> <pad> <pad> E U <pad> <pad> H | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

--> Getting baseline test results...
Baseline Test WER: 0.318
--> Showing some baseline prediction errors...
                                         target_text                                           pred_str
0                                               YEAH                                             YES NO
1                                               YEAH                                                YES
2                                          WAIT WHAT                                          WAIT WHAT
3                                                YES                                                YES
4  MMM WHEN YOU LIKE HAVE SOME WATER YOU WANNA KN...  WHEN YOU LIKE HAVE SOME WATER YOU WANT TO KNOW...
5  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...
6                                               YEAH                                           MONSIEUR
7                         FOR WAIT UM YEAH BASICALLY                              OF WHICH HUM AR BASIC
8                          I HAVEN'T GOT TO THAT YET                          I HAVEN'T GOT TO THAT YET
9                                                YUP                                                 IF
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/07/2021 11:13:26
