Wed Jul 14 10:59:10 AEST 2021
Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
  0%|          | 0/300 [00:00<?, ?ex/s]100%|██████████| 300/300 [00:00<00:00, 7998.70ex/s]
  0%|          | 0/100 [00:00<?, ?ex/s]100%|██████████| 100/100 [00:00<00:00, 7579.29ex/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 338.55ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 597.39ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 14/07/2021 10:59:11

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210714
datasetdict_id: short
use_checkpoint: False
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714
--> pretrained_mod: facebook/wav2vec2-base-960h
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  under those brads there's a wire and when the ...
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  um the cup on the right filled with washers is...
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  uhm it shows the first part of the digestive f...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                       i forgot what they're called
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the um some of the things that uh don't have i...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'X': 0, 'H': 1, 'G': 2, 'L': 3, 'E': 4, 'P': 5, 'Y': 6, 'V': 7, 'B': 8, 'F': 9, 'J': 10, 'D': 11, 'R': 12, 'I': 13, 'S': 14, ' ': 15, 'W': 16, 'T': 17, 'O': 18, 'A': 19, 'M': 20, 'K': 21, 'U': 22, 'Z': 23, "'": 24, 'N': 25, 'Q': 26, 'C': 27}
--> Vocab len: 30 
 {'X': 0, 'H': 1, 'G': 2, 'L': 3, 'E': 4, 'P': 5, 'Y': 6, 'V': 7, 'B': 8, 'F': 9, 'J': 10, 'D': 11, 'R': 12, 'I': 13, 'S': 14, 'W': 16, 'T': 17, 'O': 18, 'A': 19, 'M': 20, 'K': 21, 'U': 22, 'Z': 23, "'": 24, 'N': 25, 'Q': 26, 'C': 27, '|': 15, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


 #0:   0%|          | 0/75 [00:00<?, ?ex/s]
 #1:   0%|          | 0/75 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/75 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/75 [00:00<?, ?ex/s][A[A[A

 #2:   1%|▏         | 1/75 [00:00<00:31,  2.33ex/s][A[A
 #1:   1%|▏         | 1/75 [00:00<00:34,  2.15ex/s][A

 #2:   3%|▎         | 2/75 [00:00<00:24,  2.96ex/s][A[A


 #3:   1%|▏         | 1/75 [00:00<00:46,  1.58ex/s][A[A[A #0:   1%|▏         | 1/75 [00:00<00:50,  1.47ex/s]

 #2:   4%|▍         | 3/75 [00:00<00:19,  3.69ex/s][A[A
 #1:   3%|▎         | 2/75 [00:00<00:28,  2.52ex/s][A


 #3:   3%|▎         | 2/75 [00:00<00:34,  2.11ex/s][A[A[A

 #2:   5%|▌         | 4/75 [00:00<00:16,  4.37ex/s][A[A #0:   5%|▌         | 4/75 [00:00<00:34,  2.04ex/s]
 #1:   5%|▌         | 4/75 [00:00<00:21,  3.34ex/s][A


 #3:   9%|▉         | 7/75 [00:00<00:23,  2.96ex/s][A[A[A #0:  12%|█▏        | 9/75 [00:00<00:23,  2.85ex/s]


 #3:  15%|█▍        | 11/75 [00:00<00:15,  4.08ex/s][A[A[A
 #1:   8%|▊         | 6/75 [00:00<00:15,  4.42ex/s][A

 #2:  13%|█▎        | 10/75 [00:01<00:11,  5.82ex/s][A[A #0:  17%|█▋        | 13/75 [00:01<00:15,  3.94ex/s]
 #1:  16%|█▌        | 12/75 [00:01<00:10,  6.11ex/s][A
 #1:  29%|██▉       | 22/75 [00:01<00:06,  8.49ex/s][A #0:  21%|██▏       | 16/75 [00:01<00:11,  5.27ex/s]

 #2:  16%|█▌        | 12/75 [00:01<00:08,  7.07ex/s][A[A
 #1:  49%|████▉     | 37/75 [00:01<00:03, 11.85ex/s][A

 #2:  24%|██▍       | 18/75 [00:01<00:05,  9.53ex/s][A[A #0:  29%|██▉       | 22/75 [00:01<00:07,  7.13ex/s]


 #3:  23%|██▎       | 17/75 [00:01<00:11,  5.25ex/s][A[A[A
 #1:  61%|██████▏   | 46/75 [00:01<00:01, 16.01ex/s][A

 #2:  36%|███▌      | 27/75 [00:01<00:03, 12.95ex/s][A[A


 #3:  29%|██▉       | 22/75 [00:01<00:07,  7.13ex/s][A[A[A #0:  33%|███▎      | 25/75 [00:01<00:05,  8.93ex/s]
 #1:  75%|███████▍  | 56/75 [00:01<00:00, 21.31ex/s][A

 #2:  47%|████▋     | 35/75 [00:01<00:02, 17.15ex/s][A[A


 #3:  40%|████      | 30/75 [00:01<00:04,  9.76ex/s][A[A[A
 #1:  87%|████████▋ | 65/75 [00:01<00:00, 27.36ex/s][A

 #2:  59%|█████▊    | 44/75 [00:01<00:01, 22.59ex/s][A[A #1: 100%|██████████| 75/75 [00:01<00:00, 44.83ex/s] #0:  37%|███▋      | 28/75 [00:01<00:04,  9.62ex/s]

 #2:  79%|███████▊  | 59/75 [00:01<00:00, 30.22ex/s][A[A


 #3:  48%|████▊     | 36/75 [00:01<00:03, 12.30ex/s][A[A[A #0:  43%|████▎     | 32/75 [00:01<00:03, 12.36ex/s]

 #2:  97%|█████████▋| 73/75 [00:01<00:00, 39.04ex/s][A[A


 #3:  63%|██████▎   | 47/75 [00:01<00:01, 16.77ex/s][A[A[A #2: 100%|██████████| 75/75 [00:01<00:00, 39.38ex/s] #0:  48%|████▊     | 36/75 [00:01<00:02, 14.61ex/s]


 #3:  71%|███████   | 53/75 [00:01<00:01, 20.48ex/s][A[A[A #0:  56%|█████▌    | 42/75 [00:02<00:01, 18.62ex/s]


 #3:  81%|████████▏ | 61/75 [00:02<00:00, 26.10ex/s][A[A[A #0:  68%|██████▊   | 51/75 [00:02<00:00, 24.40ex/s]


 #3:  99%|█████████▊| 74/75 [00:02<00:00, 34.30ex/s][A[A[A #3: 100%|██████████| 75/75 [00:02<00:00, 34.00ex/s] #0:  76%|███████▌  | 57/75 [00:02<00:00, 26.65ex/s] #0:  83%|████████▎ | 62/75 [00:02<00:00, 18.68ex/s] #0: 100%|██████████| 75/75 [00:02<00:00, 25.92ex/s]



 #0:   0%|          | 0/25 [00:00<?, ?ex/s]
 #1:   0%|          | 0/25 [00:00<?, ?ex/s][A

 #2:   0%|          | 0/25 [00:00<?, ?ex/s][A[A


 #3:   0%|          | 0/25 [00:00<?, ?ex/s][A[A[A
 #1:   4%|▍         | 1/25 [00:00<00:03,  7.72ex/s][A

 #2:   4%|▍         | 1/25 [00:00<00:03,  6.07ex/s][A[A #0:   4%|▍         | 1/25 [00:00<00:05,  4.65ex/s]


 #3:   8%|▊         | 2/25 [00:00<00:02,  8.45ex/s][A[A[A
 #1:  24%|██▍       | 6/25 [00:00<00:01,  9.89ex/s][A

 #2:  16%|█▌        | 4/25 [00:00<00:02,  7.73ex/s][A[A #0:   8%|▊         | 2/25 [00:00<00:04,  5.16ex/s]


 #3:  16%|█▌        | 4/25 [00:00<00:02,  9.55ex/s][A[A[A
 #1:  68%|██████▊   | 17/25 [00:00<00:00, 13.55ex/s][A

 #2:  44%|████▍     | 11/25 [00:00<00:01, 10.53ex/s][A[A #1: 100%|██████████| 25/25 [00:00<00:00, 53.57ex/s] #0:  20%|██        | 5/25 [00:00<00:03,  6.58ex/s]


 #3:  60%|██████    | 15/25 [00:00<00:00, 12.82ex/s][A[A[A

 #2:  84%|████████▍ | 21/25 [00:00<00:00, 14.06ex/s][A[A #0:  44%|████▍     | 11/25 [00:00<00:01,  8.96ex/s] #3: 100%|██████████| 25/25 [00:00<00:00, 40.13ex/s] #2: 100%|██████████| 25/25 [00:00<00:00, 39.31ex/s] #0:  80%|████████  | 20/25 [00:00<00:00, 12.25ex/s] #0: 100%|██████████| 25/25 [00:00<00:00, 31.49ex/s]



--> Verifying data with a random sample...
Target text: CENTIMETERS AND METERS AND FOOT AND STUFF
Input array shape: (82016,)
Sampling rate: 16000
 #0:   0%|          | 0/10 [00:00<?, ?ba/s]
 #1:   0%|          | 0/10 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/10 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  10%|█         | 1/10 [00:00<00:02,  3.33ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  10%|█         | 1/10 [00:00<00:02,  3.18ba/s][A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  10%|█         | 1/10 [00:00<00:02,  3.01ba/s][A

 #2:  20%|██        | 2/10 [00:00<00:02,  3.25ba/s][A[A
 #1:  20%|██        | 2/10 [00:00<00:02,  3.01ba/s][A


 #3:  20%|██        | 2/10 [00:00<00:02,  3.19ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  10%|█         | 1/10 [00:00<00:06,  1.34ba/s]
 #1:  30%|███       | 3/10 [00:00<00:02,  3.42ba/s][A

 #2:  30%|███       | 3/10 [00:01<00:02,  2.98ba/s][A[A


 #3:  30%|███       | 3/10 [00:01<00:02,  2.59ba/s][A[A[A
 #1:  40%|████      | 4/10 [00:01<00:01,  3.21ba/s][A #0:  20%|██        | 2/10 [00:01<00:05,  1.45ba/s]

 #2:  40%|████      | 4/10 [00:01<00:02,  2.89ba/s][A[A
 #1:  50%|█████     | 5/10 [00:01<00:01,  3.51ba/s][A
 #1:  60%|██████    | 6/10 [00:01<00:00,  4.14ba/s][A

 #2:  50%|█████     | 5/10 [00:01<00:01,  2.73ba/s][A[A


 #3:  40%|████      | 4/10 [00:01<00:02,  2.23ba/s][A[A[A
 #1:  70%|███████   | 7/10 [00:01<00:00,  3.85ba/s][A #0:  30%|███       | 3/10 [00:01<00:04,  1.51ba/s]

 #2:  60%|██████    | 6/10 [00:01<00:01,  3.15ba/s][A[A
 #1:  80%|████████  | 8/10 [00:02<00:00,  3.80ba/s][A


 #3:  50%|█████     | 5/10 [00:02<00:02,  2.23ba/s][A[A[A #0:  40%|████      | 4/10 [00:02<00:03,  1.65ba/s]

 #2:  70%|███████   | 7/10 [00:02<00:01,  2.86ba/s][A[A
 #1:  90%|█████████ | 9/10 [00:02<00:00,  3.64ba/s][A #1: 100%|██████████| 10/10 [00:02<00:00,  3.96ba/s]


 #3:  60%|██████    | 6/10 [00:02<00:01,  2.41ba/s][A[A[A #0:  50%|█████     | 5/10 [00:02<00:02,  1.80ba/s]

 #2:  80%|████████  | 8/10 [00:02<00:00,  2.59ba/s][A[A


 #3:  70%|███████   | 7/10 [00:03<00:01,  2.37ba/s][A[A[A

 #2:  90%|█████████ | 9/10 [00:03<00:00,  2.80ba/s][A[A #0:  60%|██████    | 6/10 [00:03<00:02,  1.91ba/s]

 #2: 100%|██████████| 10/10 [00:03<00:00,  3.36ba/s][A[A #2: 100%|██████████| 10/10 [00:03<00:00,  2.99ba/s]


 #3:  80%|████████  | 8/10 [00:03<00:00,  2.24ba/s][A[A[A #0:  70%|███████   | 7/10 [00:03<00:01,  1.90ba/s]


 #3:  90%|█████████ | 9/10 [00:03<00:00,  2.27ba/s][A[A[A


 #3: 100%|██████████| 10/10 [00:04<00:00,  2.88ba/s][A[A[A #3: 100%|██████████| 10/10 [00:04<00:00,  2.45ba/s] #0:  80%|████████  | 8/10 [00:04<00:01,  1.97ba/s] #0:  90%|█████████ | 9/10 [00:04<00:00,  2.52ba/s] #0: 100%|██████████| 10/10 [00:04<00:00,  2.25ba/s]



 #0:   0%|          | 0/4 [00:00<?, ?ba/s]
 #1:   0%|          | 0/4 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/4 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/4 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  25%|██▌       | 1/4 [00:00<00:00,  3.77ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  25%|██▌       | 1/4 [00:00<00:01,  2.60ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  25%|██▌       | 1/4 [00:00<00:01,  2.75ba/s][A[A[A


 #3:  50%|█████     | 2/4 [00:00<00:00,  3.22ba/s][A[A[A #0:  50%|█████     | 2/4 [00:00<00:00,  3.44ba/s]
 #1:  50%|█████     | 2/4 [00:00<00:00,  2.98ba/s][A


 #3:  75%|███████▌  | 3/4 [00:00<00:00,  3.84ba/s][A[A[A #3: 100%|██████████| 4/4 [00:00<00:00,  5.55ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  25%|██▌       | 1/4 [00:00<00:02,  1.24ba/s][A[A #0:  75%|███████▌  | 3/4 [00:00<00:00,  3.43ba/s]
 #1:  75%|███████▌  | 3/4 [00:00<00:00,  2.95ba/s][A #1: 100%|██████████| 4/4 [00:01<00:00,  3.92ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  3.82ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  3.63ba/s]

 #2:  50%|█████     | 2/4 [00:01<00:01,  1.50ba/s][A[A

 #2:  75%|███████▌  | 3/4 [00:01<00:00,  1.60ba/s][A[A #2: 100%|██████████| 4/4 [00:01<00:00,  2.30ba/s]



Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 40
  Gradient Accumulation steps = 1
  Total optimization steps = 160
  0%|          | 0/160 [00:00<?, ?it/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  1%|          | 1/160 [00:10<28:10, 10.63s/it]  1%|▏         | 2/160 [00:14<22:51,  8.68s/it]  2%|▏         | 3/160 [00:19<19:20,  7.39s/it]  2%|▎         | 4/160 [00:25<18:28,  7.11s/it]  3%|▎         | 5/160 [00:31<17:24,  6.74s/it]  4%|▍         | 6/160 [00:35<15:06,  5.89s/it]  4%|▍         | 7/160 [00:39<13:54,  5.45s/it]  5%|▌         | 8/160 [00:42<11:31,  4.55s/it]  6%|▌         | 9/160 [00:48<12:47,  5.08s/it]  6%|▋         | 10/160 [00:54<13:24,  5.36s/it]  7%|▋         | 11/160 [01:00<13:51,  5.58s/it]  8%|▊         | 12/160 [01:05<12:58,  5.26s/it]  8%|▊         | 13/160 [01:08<11:45,  4.80s/it]  9%|▉         | 14/160 [01:13<11:35,  4.76s/it]  9%|▉         | 15/160 [01:17<11:02,  4.57s/it] 10%|█         | 16/160 [01:19<09:12,  3.84s/it] 11%|█         | 17/160 [01:26<11:19,  4.75s/it] 11%|█▏        | 18/160 [01:30<10:53,  4.60s/it] 12%|█▏        | 19/160 [01:35<10:36,  4.51s/it] 12%|█▎        | 20/160 [01:41<11:28,  4.92s/it] 13%|█▎        | 21/160 [01:45<10:45,  4.64s/it] 14%|█▍        | 22/160 [01:48<10:06,  4.40s/it] 14%|█▍        | 23/160 [01:55<11:40,  5.12s/it] 15%|█▌        | 24/160 [01:58<09:37,  4.25s/it] 16%|█▌        | 25/160 [02:04<11:21,  5.05s/it] 16%|█▋        | 26/160 [02:10<11:46,  5.27s/it] 17%|█▋        | 27/160 [02:15<11:07,  5.02s/it] 18%|█▊        | 28/160 [02:20<11:10,  5.08s/it] 18%|█▊        | 29/160 [02:24<10:42,  4.90s/it] 19%|█▉        | 30/160 [02:28<09:55,  4.58s/it] 19%|█▉        | 31/160 [02:35<11:18,  5.26s/it] 20%|██        | 32/160 [02:37<09:12,  4.32s/it] 21%|██        | 33/160 [02:44<10:43,  5.06s/it] 21%|██▏       | 34/160 [02:49<10:37,  5.06s/it] 22%|██▏       | 35/160 [02:53<10:03,  4.82s/it] 22%|██▎       | 36/160 [02:58<09:37,  4.65s/it] 23%|██▎       | 37/160 [03:04<10:26,  5.09s/it] 24%|██▍       | 38/160 [03:10<11:07,  5.47s/it] 24%|██▍       | 39/160 [03:14<10:11,  5.06s/it] 25%|██▌       | 40/160 [03:16<08:04,  4.04s/it] 26%|██▌       | 41/160 [03:22<09:24,  4.74s/it] 26%|██▋       | 42/160 [03:27<09:20,  4.75s/it] 27%|██▋       | 43/160 [03:32<09:14,  4.74s/it] 28%|██▊       | 44/160 [03:38<10:07,  5.24s/it] 28%|██▊       | 45/160 [03:42<09:28,  4.95s/it] 29%|██▉       | 46/160 [03:45<08:17,  4.36s/it] 29%|██▉       | 47/160 [03:49<07:53,  4.19s/it] 30%|███       | 48/160 [03:51<06:45,  3.62s/it] 31%|███       | 49/160 [03:58<08:33,  4.62s/it] 31%|███▏      | 50/160 [04:02<08:03,  4.40s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50/preprocessor_config.json
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 32%|███▏      | 51/160 [04:09<09:17,  5.12s/it] 32%|███▎      | 52/160 [04:16<10:01,  5.57s/it] 33%|███▎      | 53/160 [04:20<09:31,  5.34s/it] 34%|███▍      | 54/160 [04:25<08:46,  4.97s/it] 34%|███▍      | 55/160 [04:30<08:53,  5.08s/it] 35%|███▌      | 56/160 [04:32<07:31,  4.34s/it] 36%|███▌      | 57/160 [04:39<08:45,  5.10s/it] 36%|███▋      | 58/160 [04:46<09:38,  5.68s/it] 37%|███▋      | 59/160 [04:50<08:20,  4.95s/it] 38%|███▊      | 60/160 [04:54<08:02,  4.82s/it] 38%|███▊      | 61/160 [04:59<07:46,  4.71s/it] 39%|███▉      | 62/160 [05:05<08:36,  5.27s/it] 39%|███▉      | 63/160 [05:10<08:07,  5.03s/it] 40%|████      | 64/160 [05:12<06:38,  4.15s/it] 41%|████      | 65/160 [05:19<07:51,  4.97s/it] 41%|████▏     | 66/160 [05:23<07:19,  4.68s/it] 42%|████▏     | 67/160 [05:26<06:50,  4.41s/it] 42%|████▎     | 68/160 [05:33<07:49,  5.10s/it] 43%|████▎     | 69/160 [05:39<08:17,  5.46s/it] 44%|████▍     | 70/160 [05:44<07:44,  5.16s/it] 44%|████▍     | 71/160 [05:48<07:12,  4.86s/it] 45%|████▌     | 72/160 [05:50<05:48,  3.96s/it] 46%|████▌     | 73/160 [05:56<06:41,  4.61s/it] 46%|████▋     | 74/160 [06:00<06:30,  4.54s/it] 47%|████▋     | 75/160 [06:05<06:21,  4.49s/it] 48%|████▊     | 76/160 [06:11<07:10,  5.12s/it] 48%|████▊     | 77/160 [06:16<07:03,  5.10s/it] 49%|████▉     | 78/160 [06:21<06:41,  4.89s/it] 49%|████▉     | 79/160 [06:27<07:11,  5.33s/it] 50%|█████     | 80/160 [06:29<05:51,  4.39s/it] 51%|█████     | 81/160 [06:35<06:24,  4.87s/it] 51%|█████▏    | 82/160 [06:40<06:15,  4.81s/it] 52%|█████▏    | 83/160 [06:45<06:11,  4.82s/it] 52%|█████▎    | 84/160 [06:51<06:27,  5.09s/it] 53%|█████▎    | 85/160 [06:55<06:11,  4.96s/it] 54%|█████▍    | 86/160 [07:00<05:56,  4.81s/it] 54%|█████▍    | 87/160 [07:03<05:21,  4.41s/it] 55%|█████▌    | 88/160 [07:05<04:31,  3.76s/it] 56%|█████▌    | 89/160 [07:12<05:32,  4.68s/it] 56%|█████▋    | 90/160 [07:17<05:19,  4.57s/it] 57%|█████▋    | 91/160 [07:23<05:57,  5.18s/it] 57%|█████▊    | 92/160 [07:28<05:40,  5.01s/it] 58%|█████▊    | 93/160 [07:32<05:22,  4.81s/it] 59%|█████▉    | 94/160 [07:36<05:04,  4.61s/it] 59%|█████▉    | 95/160 [07:40<04:39,  4.30s/it] 60%|██████    | 96/160 [07:41<03:41,  3.47s/it] 61%|██████    | 97/160 [07:48<04:33,  4.35s/it] 61%|██████▏   | 98/160 [07:53<04:52,  4.71s/it] 62%|██████▏   | 99/160 [08:00<05:13,  5.15s/it] 62%|██████▎   | 100/160 [08:04<05:01,  5.02s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100/preprocessor_config.json
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 63%|██████▎   | 101/160 [08:12<05:45,  5.86s/it] 64%|██████▍   | 102/160 [08:16<05:08,  5.33s/it] 64%|██████▍   | 103/160 [08:21<04:48,  5.07s/it] 65%|██████▌   | 104/160 [08:23<03:54,  4.19s/it] 66%|██████▌   | 105/160 [08:29<04:29,  4.90s/it] 66%|██████▋   | 106/160 [08:33<04:11,  4.66s/it] 67%|██████▋   | 107/160 [08:39<04:23,  4.97s/it] 68%|██████▊   | 108/160 [08:44<04:16,  4.94s/it] 68%|██████▊   | 109/160 [08:50<04:24,  5.19s/it] 69%|██████▉   | 110/160 [08:54<04:03,  4.86s/it] 69%|██████▉   | 111/160 [08:58<03:46,  4.62s/it] 70%|███████   | 112/160 [09:00<03:09,  3.94s/it] 71%|███████   | 113/160 [09:07<03:37,  4.64s/it] 71%|███████▏  | 114/160 [09:11<03:29,  4.56s/it] 72%|███████▏  | 115/160 [09:16<03:27,  4.60s/it] 72%|███████▎  | 116/160 [09:22<03:44,  5.10s/it] 73%|███████▎  | 117/160 [09:25<03:14,  4.52s/it] 74%|███████▍  | 118/160 [09:29<03:07,  4.47s/it] 74%|███████▍  | 119/160 [09:34<03:02,  4.46s/it] 75%|███████▌  | 120/160 [09:36<02:31,  3.78s/it] 76%|███████▌  | 121/160 [09:42<02:56,  4.54s/it] 76%|███████▋  | 122/160 [09:47<02:53,  4.57s/it] 77%|███████▋  | 123/160 [09:50<02:35,  4.20s/it] 78%|███████▊  | 124/160 [09:55<02:33,  4.25s/it] 78%|███████▊  | 125/160 [10:01<02:54,  4.99s/it] 79%|███████▉  | 126/160 [10:05<02:38,  4.65s/it] 79%|███████▉  | 127/160 [10:09<02:29,  4.54s/it] 80%|████████  | 128/160 [10:13<02:13,  4.16s/it] 81%|████████  | 129/160 [10:19<02:28,  4.79s/it] 81%|████████▏ | 130/160 [10:24<02:22,  4.74s/it] 82%|████████▏ | 131/160 [10:27<02:01,  4.18s/it] 82%|████████▎ | 132/160 [10:33<02:12,  4.75s/it] 83%|████████▎ | 133/160 [10:36<02:00,  4.46s/it] 84%|████████▍ | 134/160 [10:40<01:50,  4.26s/it] 84%|████████▍ | 135/160 [10:46<02:01,  4.87s/it] 85%|████████▌ | 136/160 [10:49<01:37,  4.06s/it] 86%|████████▌ | 137/160 [10:55<01:50,  4.80s/it] 86%|████████▋ | 138/160 [10:59<01:40,  4.56s/it] 87%|████████▋ | 139/160 [11:02<01:24,  4.00s/it] 88%|████████▊ | 140/160 [11:08<01:34,  4.74s/it] 88%|████████▊ | 141/160 [11:13<01:29,  4.72s/it] 89%|████████▉ | 142/160 [11:17<01:21,  4.52s/it] 89%|████████▉ | 143/160 [11:21<01:14,  4.38s/it] 90%|█████████ | 144/160 [11:25<01:05,  4.12s/it] 91%|█████████ | 145/160 [11:31<01:12,  4.83s/it] 91%|█████████▏| 146/160 [11:36<01:06,  4.75s/it] 92%|█████████▏| 147/160 [11:42<01:06,  5.10s/it] 92%|█████████▎| 148/160 [11:46<00:59,  4.97s/it] 93%|█████████▎| 149/160 [11:51<00:53,  4.89s/it] 94%|█████████▍| 150/160 [11:58<00:54,  5.44s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-150/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-50] due to args.save_total_limit
/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
 94%|█████████▍| 151/160 [12:06<00:56,  6.33s/it] 95%|█████████▌| 152/160 [12:08<00:40,  5.10s/it] 96%|█████████▌| 153/160 [12:14<00:37,  5.39s/it] 96%|█████████▋| 154/160 [12:18<00:29,  5.00s/it] 97%|█████████▋| 155/160 [12:23<00:24,  4.87s/it] 98%|█████████▊| 156/160 [12:28<00:19,  4.79s/it] 98%|█████████▊| 157/160 [12:32<00:14,  4.74s/it] 99%|█████████▉| 158/160 [12:38<00:10,  5.06s/it] 99%|█████████▉| 159/160 [12:42<00:04,  4.79s/it]100%|██████████| 160/160 [12:46<00:00,  4.44s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 160/160 [12:46<00:00,  4.44s/it]100%|██████████| 160/160 [12:46<00:00,  4.79s/it]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/pytorch_model.bin
loading feature extractor configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/preprocessor_config.json
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/added_tokens.json. We won't load it.
Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/tokenizer.json. We won't load it.
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/vocab.json
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/tokenizer_config.json
loading file None
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/special_tokens_map.json
loading file None
loading configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/config.json
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/pytorch_model.bin
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.24ex/s]  5%|▌         | 5/100 [00:00<00:10,  9.46ex/s]  8%|▊         | 8/100 [00:00<00:07, 11.87ex/s] 11%|█         | 11/100 [00:00<00:07, 12.70ex/s] 14%|█▍        | 14/100 [00:00<00:05, 14.44ex/s] 16%|█▌        | 16/100 [00:00<00:05, 15.46ex/s] 19%|█▉        | 19/100 [00:00<00:04, 16.33ex/s] 22%|██▏       | 22/100 [00:01<00:04, 18.66ex/s] 25%|██▌       | 25/100 [00:01<00:05, 14.46ex/s] 28%|██▊       | 28/100 [00:01<00:04, 16.24ex/s] 31%|███       | 31/100 [00:01<00:03, 18.29ex/s] 34%|███▍      | 34/100 [00:01<00:03, 17.99ex/s] 37%|███▋      | 37/100 [00:01<00:03, 19.13ex/s] 40%|████      | 40/100 [00:02<00:02, 20.18ex/s] 43%|████▎     | 43/100 [00:02<00:02, 19.39ex/s] 47%|████▋     | 47/100 [00:02<00:02, 21.95ex/s] 50%|█████     | 50/100 [00:02<00:02, 17.94ex/s] 53%|█████▎    | 53/100 [00:02<00:02, 15.86ex/s] 55%|█████▌    | 55/100 [00:03<00:03, 12.17ex/s] 58%|█████▊    | 58/100 [00:03<00:03, 10.92ex/s] 61%|██████    | 61/100 [00:03<00:02, 13.24ex/s] 63%|██████▎   | 63/100 [00:03<00:02, 13.48ex/s] 65%|██████▌   | 65/100 [00:03<00:02, 14.00ex/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.32ex/s] 71%|███████   | 71/100 [00:04<00:01, 15.13ex/s] 73%|███████▎  | 73/100 [00:04<00:02, 11.25ex/s] 75%|███████▌  | 75/100 [00:04<00:02, 12.14ex/s] 77%|███████▋  | 77/100 [00:04<00:02, 11.40ex/s] 80%|████████  | 80/100 [00:04<00:01, 13.91ex/s] 85%|████████▌ | 85/100 [00:05<00:00, 15.10ex/s] 89%|████████▉ | 89/100 [00:05<00:00, 18.27ex/s] 95%|█████████▌| 95/100 [00:05<00:00, 22.89ex/s] 99%|█████████▉| 99/100 [00:05<00:00, 23.37ex/s]100%|██████████| 100/100 [00:05<00:00, 17.80ex/s]
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.59ex/s]  5%|▌         | 5/100 [00:00<00:09,  9.87ex/s]  8%|▊         | 8/100 [00:00<00:07, 12.27ex/s] 11%|█         | 11/100 [00:00<00:06, 12.97ex/s] 14%|█▍        | 14/100 [00:00<00:05, 14.61ex/s] 16%|█▌        | 16/100 [00:00<00:05, 15.57ex/s] 19%|█▉        | 19/100 [00:00<00:04, 16.29ex/s] 22%|██▏       | 22/100 [00:01<00:04, 18.54ex/s] 25%|██▌       | 25/100 [00:01<00:05, 14.44ex/s] 27%|██▋       | 27/100 [00:01<00:04, 15.68ex/s] 31%|███       | 31/100 [00:01<00:03, 17.80ex/s] 34%|███▍      | 34/100 [00:01<00:03, 17.55ex/s] 36%|███▌      | 36/100 [00:01<00:03, 17.61ex/s] 39%|███▉      | 39/100 [00:02<00:03, 19.18ex/s] 42%|████▏     | 42/100 [00:02<00:02, 19.75ex/s] 45%|████▌     | 45/100 [00:02<00:02, 21.58ex/s] 48%|████▊     | 48/100 [00:02<00:02, 18.33ex/s] 51%|█████     | 51/100 [00:02<00:02, 16.84ex/s] 53%|█████▎    | 53/100 [00:02<00:02, 15.76ex/s] 55%|█████▌    | 55/100 [00:03<00:03, 12.04ex/s] 58%|█████▊    | 58/100 [00:03<00:03, 10.79ex/s] 61%|██████    | 61/100 [00:03<00:02, 13.08ex/s] 63%|██████▎   | 63/100 [00:03<00:02, 13.36ex/s] 65%|██████▌   | 65/100 [00:03<00:02, 13.95ex/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.36ex/s] 71%|███████   | 71/100 [00:04<00:01, 15.20ex/s] 73%|███████▎  | 73/100 [00:04<00:02, 11.48ex/s] 75%|███████▌  | 75/100 [00:04<00:02, 12.25ex/s] 77%|███████▋  | 77/100 [00:04<00:01, 11.53ex/s] 80%|████████  | 80/100 [00:04<00:01, 14.06ex/s] 85%|████████▌ | 85/100 [00:05<00:00, 16.16ex/s] 87%|████████▋ | 87/100 [00:05<00:00, 16.47ex/s] 92%|█████████▏| 92/100 [00:05<00:00, 20.42ex/s] 97%|█████████▋| 97/100 [00:05<00:00, 22.04ex/s]100%|██████████| 100/100 [00:05<00:00, 17.69ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 766.353, 'train_samples_per_second': 7.829, 'train_steps_per_second': 0.209, 'train_loss': 1.5303815841674804, 'epoch': 20.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.270
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YEAR WE WE DON'T REALLY DO T WITH ANYTHING ELS...
2                                               YEAH                                           MONSIEUR
3                                               YEAH                                              YESNO
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO WHEV WE PULL IT UP UP AND THEN WE PUSH IT D...
5                                       THAT SLIPPED                                        HUSHTHATWIP
6                                        UH HUH YEAH                                               I AM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...  YEANO IT WAS A MILLER LEAT NO A HUNDRED MILL L...
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE BECAUSE WE WANDERED ...
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> E E A H H <pad> <pad> | <pad> W <pad> <pad> E <pad> <pad> | <pad> W R R R <pad> O <pad> <pad> <pad> T E <pad> | <pad> O U <pad> R E <pad> | | | <pad> N <pad> U <pad> M <pad> <pad> B <pad> E R R <pad> <pad> <pad> | | D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O U <pad> <pad> <pad> <pad> T T <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y <pad> <pad> <pad> E U <pad> <pad> H | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

--> Getting baseline test results...
Baseline Test WER: 0.318
--> Showing some baseline prediction errors...
                                         target_text                                           pred_str
0                                               YEAH                                             YES NO
1                                               YEAH                                                YES
2                                          WAIT WHAT                                          WAIT WHAT
3                                                YES                                                YES
4  MMM WHEN YOU LIKE HAVE SOME WATER YOU WANNA KN...  WHEN YOU LIKE HAVE SOME WATER YOU WANT TO KNOW...
5  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...
6                                               YEAH                                           MONSIEUR
7                         FOR WAIT UM YEAH BASICALLY                              OF WHICH HUM AR BASIC
8                          I HAVEN'T GOT TO THAT YET                          I HAVEN'T GOT TO THAT YET
9                                                YUP                                                 IF
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/07/2021 11:13:26
