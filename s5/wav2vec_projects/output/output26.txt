Using custom data configuration default-8e619efe0a15e986
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-06d039fe7168d513.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6bc264a654a4cf85.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 115.21ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 610.88ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_checkpoint.py
Started: 11/07/2021 18:01:50

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_og_test.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/20210711
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210711.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711
--> pretrained_mod: facebook/wav2vec2-base
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-20210711

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  um i forget its name but i think it starts wit...
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the d cell is a source of el electricity to tu...
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  they mean that the wires on the motor stop the...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the motor um i mean the d cell helps you helps...
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  you connect the wires to it and then it flows ...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'C': 0, 'B': 1, 'V': 2, 'I': 3, 'P': 4, 'R': 5, 'X': 6, 'Q': 7, 'A': 8, 'M': 9, 'N': 10, 'Y': 11, 'D': 12, 'L': 13, 'O': 14, 'Z': 15, 'E': 16, 'J': 17, 'H': 18, 'U': 19, ' ': 20, 'K': 21, 'F': 22, 'T': 23, "'": 24, 'W': 25, 'S': 26, 'G': 27}
--> Vocab len: 30 
 {'C': 0, 'B': 1, 'V': 2, 'I': 3, 'P': 4, 'R': 5, 'X': 6, 'Q': 7, 'A': 8, 'M': 9, 'N': 10, 'Y': 11, 'D': 12, 'L': 13, 'O': 14, 'Z': 15, 'E': 16, 'J': 17, 'H': 18, 'U': 19, 'K': 21, 'F': 22, 'T': 23, "'": 24, 'W': 25, 'S': 26, 'G': 27, '|': 20, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210711.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6548d21f1ad6832c.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-a4f938df68c0e73a.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-34663d1eabd2a027.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-71935b26105c2e03.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dabc0f195246f655.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-4c3d13f91f090c96.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-df96aac77f6feb0c.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/20210711/csv/default-8e619efe0a15e986/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-322c8293d52d0e19.arrow
--> Verifying data with a random sample...
Target text: GOOD
Input array shape: (11504,)
Sampling rate: 16000
 #0:   0%|          | 0/1 [00:00<?, ?ba/s]
 #1:   0%|          | 0/1 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/1 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2: 100%|██████████| 1/1 [00:00<00:00,  5.58ba/s][A[A #2: 100%|██████████| 1/1 [00:00<00:00,  5.56ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3: 100%|██████████| 1/1 [00:00<00:00,  5.44ba/s][A[A[A #3: 100%|██████████| 1/1 [00:00<00:00,  5.43ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1: 100%|██████████| 1/1 [00:00<00:00,  3.54ba/s][A #1: 100%|██████████| 1/1 [00:00<00:00,  3.54ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0: 100%|██████████| 1/1 [00:00<00:00,  2.46ba/s] #0: 100%|██████████| 1/1 [00:00<00:00,  2.46ba/s]



 #0:   0%|          | 0/4 [00:00<?, ?ba/s]
 #1:   0%|          | 0/4 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/4 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/4 [00:00<?, ?ba/s][A[A[A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
 #0:  25%|██▌       | 1/4 [00:00<00:00,  4.06ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

 #1:  25%|██▌       | 1/4 [00:00<00:01,  2.84ba/s][A/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)



 #3:  25%|██▌       | 1/4 [00:00<00:01,  2.84ba/s][A[A[A


 #3:  50%|█████     | 2/4 [00:00<00:00,  3.37ba/s][A[A[A
 #1:  50%|█████     | 2/4 [00:00<00:00,  3.28ba/s][A #0:  50%|█████     | 2/4 [00:00<00:00,  3.74ba/s]


 #3:  75%|███████▌  | 3/4 [00:00<00:00,  4.05ba/s][A[A[A #3: 100%|██████████| 4/4 [00:00<00:00,  5.95ba/s]/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)


 #2:  25%|██▌       | 1/4 [00:00<00:02,  1.36ba/s][A[A #0:  75%|███████▌  | 3/4 [00:00<00:00,  3.75ba/s]
 #1:  75%|███████▌  | 3/4 [00:00<00:00,  3.30ba/s][A #1: 100%|██████████| 4/4 [00:00<00:00,  4.43ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  4.18ba/s] #0: 100%|██████████| 4/4 [00:01<00:00,  3.98ba/s]

 #2:  50%|█████     | 2/4 [00:01<00:01,  1.64ba/s][A[A

 #2:  75%|███████▌  | 3/4 [00:01<00:00,  1.76ba/s][A[A #2: 100%|██████████| 4/4 [00:01<00:00,  2.56ba/s]


Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 10
  Num Epochs = 1
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 1
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:01<00:00,  1.23s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                             100%|██████████| 1/1 [00:01<00:00,  1.23s/it]100%|██████████| 1/1 [00:01<00:00,  1.23s/it]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210711/pytorch_model.bin
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.46ex/s]  5%|▌         | 5/100 [00:00<00:09,  9.71ex/s]  8%|▊         | 8/100 [00:00<00:07, 12.12ex/s] 11%|█         | 11/100 [00:00<00:06, 12.93ex/s] 14%|█▍        | 14/100 [00:00<00:05, 14.62ex/s] 16%|█▌        | 16/100 [00:00<00:05, 15.63ex/s] 19%|█▉        | 19/100 [00:00<00:04, 16.33ex/s] 22%|██▏       | 22/100 [00:01<00:04, 18.66ex/s] 25%|██▌       | 25/100 [00:01<00:05, 14.68ex/s] 28%|██▊       | 28/100 [00:01<00:04, 16.43ex/s] 31%|███       | 31/100 [00:01<00:03, 18.44ex/s] 34%|███▍      | 34/100 [00:01<00:03, 18.02ex/s] 36%|███▌      | 36/100 [00:01<00:03, 18.03ex/s] 39%|███▉      | 39/100 [00:02<00:03, 19.56ex/s] 42%|████▏     | 42/100 [00:02<00:02, 20.13ex/s] 45%|████▌     | 45/100 [00:02<00:02, 21.92ex/s] 48%|████▊     | 48/100 [00:02<00:02, 18.72ex/s] 51%|█████     | 51/100 [00:02<00:02, 17.23ex/s] 53%|█████▎    | 53/100 [00:02<00:02, 16.17ex/s] 55%|█████▌    | 55/100 [00:03<00:03, 12.43ex/s] 58%|█████▊    | 58/100 [00:03<00:03, 11.01ex/s] 61%|██████    | 61/100 [00:03<00:02, 13.31ex/s] 63%|██████▎   | 63/100 [00:03<00:02, 13.57ex/s] 65%|██████▌   | 65/100 [00:03<00:02, 14.10ex/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.37ex/s] 71%|███████   | 71/100 [00:04<00:01, 15.15ex/s] 73%|███████▎  | 73/100 [00:04<00:02, 11.36ex/s] 75%|███████▌  | 75/100 [00:04<00:02, 12.22ex/s] 77%|███████▋  | 77/100 [00:04<00:02, 11.41ex/s] 80%|████████  | 80/100 [00:04<00:01, 13.93ex/s] 83%|████████▎ | 83/100 [00:05<00:01, 15.48ex/s] 85%|████████▌ | 85/100 [00:05<00:00, 15.70ex/s] 89%|████████▉ | 89/100 [00:05<00:00, 18.84ex/s] 95%|█████████▌| 95/100 [00:05<00:00, 23.53ex/s] 99%|█████████▉| 99/100 [00:05<00:00, 23.88ex/s]100%|██████████| 100/100 [00:05<00:00, 17.80ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-20210711
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 1.2293, 'train_samples_per_second': 8.135, 'train_steps_per_second': 0.814, 'train_loss': 86.5610580444336, 'epoch': 1.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting test results...
Test WER: 0.318
--> Showing some prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YEAR WE WE DON'T REALLY DO WITH ANYTHING ELSE ...
2                                               YEAH                                           MONSIEUR
3                                               YEAH                                             YES NO
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO YET WE PULL IT UP UP AND THEN WE PUSH IT DO...
5                                       THAT SLIPPED                                     OSH THAP SLIPS
6                                        UH HUH YEAH                                    EVERTHOUSA I AM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...    NO IT WAS A MILLE LY NO A HUNDRED MILLE LEADERS
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASURE MOMET HERE Y...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE CAUSE WE WANDERED TH...
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 11/07/2021 18:02:42
