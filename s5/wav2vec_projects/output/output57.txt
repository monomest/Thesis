Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-47024f6103ac1df2.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-c5b890c5844b797c.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 75.73ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 440.81ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 15/07/2021 15:06:05

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210714
datasetdict_id: short
use_checkpoint: True
checkpoint: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714
--> pretrained_mod: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  um so that there the right so that they're the...
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                               yeah
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  well this would be long right well no this one...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...              that they're muscle and they're cells
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                     to get better at it so that um
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'F': 0, 'B': 1, 'H': 2, 'C': 3, 'I': 4, 'Z': 5, 'M': 6, 'T': 7, "'": 8, ' ': 9, 'P': 10, 'Y': 11, 'L': 12, 'J': 13, 'K': 14, 'R': 15, 'E': 16, 'S': 17, 'X': 18, 'V': 19, 'N': 20, 'D': 21, 'A': 22, 'W': 23, 'U': 24, 'G': 25, 'Q': 26, 'O': 27}
--> Vocab len: 30 
 {'F': 0, 'B': 1, 'H': 2, 'C': 3, 'I': 4, 'Z': 5, 'M': 6, 'T': 7, "'": 8, 'P': 10, 'Y': 11, 'L': 12, 'J': 13, 'K': 14, 'R': 15, 'E': 16, 'S': 17, 'X': 18, 'V': 19, 'N': 20, 'D': 21, 'A': 22, 'W': 23, 'U': 24, 'G': 25, 'Q': 26, 'O': 27, '|': 9, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210714.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-b84fec576315d285.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-042d4e13c7759f68.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-32482b156ab05203.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6a15623a8b20aca3.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-897b02773dc1977b.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-78f0e24bd254b7b9.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-5fa7421341e241aa.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-45eb95a440a8bd16.arrow
--> Verifying data with a random sample...
Target text: YEAH
Input array shape: (8224,)
Sampling rate: 16000
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-fc19af87df56e3a0.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-1286bcb1181e8d45.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-452d3ba8d89d8f9e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dfcc468b38ce6b24.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-88e1fc4038eed18e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-badef0cc11e36328.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-8ede2ed0863dad80.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d2a32ed91d56d325.arrow
Using amp fp16 backend
Loading model from /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100).
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 300
  Continuing training from checkpoint, will skip to saved global_step
  Continuing training from epoch 6
  Continuing training from global step 100
  Will skip the first 6 epochs then the first 10 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.
  0%|          | 0/10 [00:00<?, ?it/s]Skipping the first batches:   0%|          | 0/10 [00:00<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s][ASkipping the first batches:  10%|â–ˆ         | 1/10 [00:13<01:58, 13.12s/it]Skipping the first batches:  20%|â–ˆâ–ˆ        | 2/10 [00:13<01:15,  9.40s/it]Skipping the first batches:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:14<00:46,  6.65s/it]Skipping the first batches:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:15<00:31,  5.20s/it]Skipping the first batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:16<00:19,  3.89s/it]Skipping the first batches:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:16<00:11,  2.80s/it]Skipping the first batches:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:18<00:07,  2.52s/it]Skipping the first batches:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:19<00:03,  1.92s/it]Skipping the first batches:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:19<00:01,  1.40s/it]Skipping the first batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  1.49s/it]--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

Traceback (most recent call last):
  File "run_finetune_kids_after-outage_short.py", line 499, in <module>
    trainer.train(pretrained_mod)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1251, in train
    self._load_rng_state(resume_from_checkpoint)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1464, in _load_rng_state
    torch.cuda.random.set_rng_state_all(checkpoint_rng_state["cuda"])
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 73, in set_rng_state_all
    set_rng_state(state, i)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 64, in set_rng_state
    _lazy_call(cb)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/__init__.py", line 114, in _lazy_call
    callable()
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 61, in cb
    default_generator = torch.cuda.default_generators[idx]
IndexError: tuple index out of range
Skipping the first batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.15s/it]
  0%|          | 0/300 [00:21<?, ?it/s]Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-47024f6103ac1df2.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-c5b890c5844b797c.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 135.95ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 574.64ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 15/07/2021 15:09:42

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210715
datasetdict_id: short
use_checkpoint: True
checkpoint: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715
--> pretrained_mod: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  this i don't know what it has to do with what ...
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                  uhm it is a metal
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  that um a lot of people use measurement to do ...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the intestines uhm absorb the water and nutrients
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  uhm we've talked about the conductors and insu...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'A': 0, 'K': 1, 'S': 2, 'O': 3, 'M': 4, 'X': 5, 'T': 6, 'Q': 7, 'P': 8, 'W': 9, 'B': 10, 'I': 11, 'L': 12, 'R': 13, 'D': 14, 'Y': 15, 'N': 16, 'F': 17, 'E': 18, ' ': 19, 'H': 20, 'G': 21, 'J': 22, 'Z': 23, 'U': 24, 'C': 25, 'V': 26, "'": 27}
--> Vocab len: 30 
 {'A': 0, 'K': 1, 'S': 2, 'O': 3, 'M': 4, 'X': 5, 'T': 6, 'Q': 7, 'P': 8, 'W': 9, 'B': 10, 'I': 11, 'L': 12, 'R': 13, 'D': 14, 'Y': 15, 'N': 16, 'F': 17, 'E': 18, 'H': 20, 'G': 21, 'J': 22, 'Z': 23, 'U': 24, 'C': 25, 'V': 26, "'": 27, '|': 19, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-b84fec576315d285.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-042d4e13c7759f68.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6a15623a8b20aca3.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-32482b156ab05203.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-897b02773dc1977b.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-78f0e24bd254b7b9.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-5fa7421341e241aa.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-45eb95a440a8bd16.arrow
--> Verifying data with a random sample...
Target text: SURE DIGESTIVE SYSTEMS CELLS THOSE ARE THE MAIN POINTS
Input array shape: (106344,)
Sampling rate: 16000
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-fc19af87df56e3a0.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-1286bcb1181e8d45.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-452d3ba8d89d8f9e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dfcc468b38ce6b24.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-88e1fc4038eed18e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-badef0cc11e36328.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-8ede2ed0863dad80.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d2a32ed91d56d325.arrow
Using amp fp16 backend
Loading model from /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210714/checkpoint-100).
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 300
  Continuing training from checkpoint, will skip to saved global_step
  Continuing training from epoch 6
  Continuing training from global step 100
  Will skip the first 6 epochs then the first 10 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.
  0%|          | 0/10 [00:00<?, ?it/s]Skipping the first batches:   0%|          | 0/10 [00:00<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s][ASkipping the first batches:  10%|â–ˆ         | 1/10 [00:13<02:00, 13.39s/it]Skipping the first batches:  20%|â–ˆâ–ˆ        | 2/10 [00:14<01:16,  9.60s/it]Skipping the first batches:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:14<00:47,  6.80s/it]Skipping the first batches:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:16<00:31,  5.32s/it]Skipping the first batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:17<00:19,  3.98s/it]Skipping the first batches:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:17<00:11,  2.86s/it]Skipping the first batches:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:19<00:07,  2.57s/it]Skipping the first batches:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:19<00:03,  1.96s/it]Skipping the first batches:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:19<00:01,  1.43s/it]Skipping the first batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  1.49s/it]--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

Traceback (most recent call last):
  File "run_finetune_kids_after-outage_short.py", line 499, in <module>
    trainer.train(pretrained_mod)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1251, in train
    self._load_rng_state(resume_from_checkpoint)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/transformers/trainer.py", line 1464, in _load_rng_state
    torch.cuda.random.set_rng_state_all(checkpoint_rng_state["cuda"])
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 73, in set_rng_state_all
    set_rng_state(state, i)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 64, in set_rng_state
    _lazy_call(cb)
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/__init__.py", line 114, in _lazy_call
    callable()
  File "/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/thesis_env/lib/python3.6/site-packages/torch/cuda/random.py", line 61, in cb
    default_generator = torch.cuda.default_generators[idx]
IndexError: tuple index out of range
Skipping the first batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/it]
  0%|          | 0/300 [00:21<?, ?it/s]Using custom data configuration default-37316b26926a9f32
Reusing dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-47024f6103ac1df2.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-c5b890c5844b797c.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 110.93ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 441.69ba/s]------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/wav2vec_projects/run_finetune_kids_after-outage_short.py
Started: 15/07/2021 15:13:03

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: 20210715
datasetdict_id: short
use_checkpoint: False
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: False
baseline_model: facebook/wav2vec2-base-960h

------> SETTING FILEPATHS... ----------------------------------------- 

--> myST_train_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_train_short.csv
--> myST_test_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/myST_test_short.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/short
--> vocab_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715.json
--> model_fp: /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715
--> pretrained_mod: facebook/wav2vec2-base-960h
--> myST_datasetdict_fp: /srv/scratch/chacmod/renee_thesis/datasetdict-short
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING MYST DATASET... ------------------------------------

--> MyST dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 300
    })
    test: Dataset({
        features: ['filepath', 'transcription'],
        num_rows: 100
    })
})
--> Printing some random samples...
                                            filepath                                      transcription
0  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                           learning about magnetism
1  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...                                               yeah
2  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  that some sides um stick and like if you put i...
3  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  the one that looks like uh sort of like a swit...
4  /srv/scratch/chacmod/MyST/myst-v0.3.0-171fbda/...  uhm i don't know uhm it looks like a circulato...
SUCCESS: Prepared dataset.

------> CREATING VOCABULARY... ---------------------------------------

--> Creating map(...) function for vocab...
--> Vocab len: 28 
 {'B': 0, 'F': 1, 'N': 2, 'C': 3, 'X': 4, 'H': 5, 'V': 6, 'Z': 7, 'M': 8, 'O': 9, 'J': 10, 'W': 11, 'U': 12, 'I': 13, 'R': 14, 'T': 15, 'L': 16, 'G': 17, 'A': 18, 'E': 19, 'P': 20, ' ': 21, 'D': 22, "'": 23, 'S': 24, 'Y': 25, 'K': 26, 'Q': 27}
--> Vocab len: 30 
 {'B': 0, 'F': 1, 'N': 2, 'C': 3, 'X': 4, 'H': 5, 'V': 6, 'Z': 7, 'M': 8, 'O': 9, 'J': 10, 'W': 11, 'U': 12, 'I': 13, 'R': 14, 'T': 15, 'L': 16, 'G': 17, 'A': 18, 'E': 19, 'P': 20, 'D': 22, "'": 23, 'S': 24, 'Y': 25, 'K': 26, 'Q': 27, '|': 21, '[UNK]': 28, '[PAD]': 29}
SUCCESS: Created vocabulary file at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/vocab_20210715.json

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 


Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-b84fec576315d285.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-32482b156ab05203.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-042d4e13c7759f68.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6a15623a8b20aca3.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-897b02773dc1977b.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-78f0e24bd254b7b9.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-5fa7421341e241aa.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-45eb95a440a8bd16.arrow
--> Verifying data with a random sample...
Target text: YEAH
Input array shape: (8224,)
Sampling rate: 16000
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-fc19af87df56e3a0.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-1286bcb1181e8d45.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dfcc468b38ce6b24.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-452d3ba8d89d8f9e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-88e1fc4038eed18e.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-8ede2ed0863dad80.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-badef0cc11e36328.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/short/csv/default-37316b26926a9f32/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d2a32ed91d56d325.arrow
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using amp fp16 backend
***** Running training *****
  Num examples = 300
  Num Epochs = 20
  Instantaneous batch size per device = 20
  Total train batch size (w. parallel, distributed & accumulation) = 20
  Gradient Accumulation steps = 1
  Total optimization steps = 300
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:06<30:05,  6.04s/it]  1%|          | 2/300 [00:07<22:32,  4.54s/it]  1%|          | 3/300 [00:07<16:27,  3.33s/it]  1%|â–         | 4/300 [00:10<15:55,  3.23s/it]  2%|â–         | 5/300 [00:11<12:48,  2.60s/it]  2%|â–         | 6/300 [00:12<09:42,  1.98s/it]  2%|â–         | 7/300 [00:16<12:53,  2.64s/it]  3%|â–Ž         | 8/300 [00:17<10:42,  2.20s/it]  3%|â–Ž         | 9/300 [00:18<08:13,  1.69s/it]  3%|â–Ž         | 10/300 [00:22<12:18,  2.55s/it]  4%|â–Ž         | 11/300 [00:23<10:14,  2.13s/it]  4%|â–         | 12/300 [00:24<07:40,  1.60s/it]  4%|â–         | 13/300 [00:27<10:10,  2.13s/it]  5%|â–         | 14/300 [00:28<08:32,  1.79s/it]  5%|â–Œ         | 15/300 [00:29<06:42,  1.41s/it]  5%|â–Œ         | 16/300 [00:33<11:23,  2.41s/it]  6%|â–Œ         | 17/300 [00:35<10:00,  2.12s/it]  6%|â–Œ         | 18/300 [00:35<07:45,  1.65s/it]  6%|â–‹         | 19/300 [00:40<11:40,  2.49s/it]  7%|â–‹         | 20/300 [00:41<09:27,  2.03s/it]  7%|â–‹         | 21/300 [00:41<07:08,  1.54s/it]  7%|â–‹         | 22/300 [00:44<09:34,  2.07s/it]  8%|â–Š         | 23/300 [00:46<08:14,  1.79s/it]  8%|â–Š         | 24/300 [00:46<06:28,  1.41s/it]  8%|â–Š         | 25/300 [00:49<08:55,  1.95s/it]  9%|â–Š         | 26/300 [00:50<07:39,  1.68s/it]  9%|â–‰         | 27/300 [00:51<05:59,  1.32s/it]  9%|â–‰         | 28/300 [00:54<08:16,  1.83s/it] 10%|â–‰         | 29/300 [00:55<07:12,  1.59s/it] 10%|â–ˆ         | 30/300 [00:55<05:43,  1.27s/it] 10%|â–ˆ         | 31/300 [01:00<09:45,  2.18s/it] 11%|â–ˆ         | 32/300 [01:01<08:14,  1.85s/it] 11%|â–ˆ         | 33/300 [01:01<06:21,  1.43s/it] 11%|â–ˆâ–        | 34/300 [01:04<08:40,  1.96s/it] 12%|â–ˆâ–        | 35/300 [01:06<07:37,  1.73s/it] 12%|â–ˆâ–        | 36/300 [01:06<05:49,  1.32s/it] 12%|â–ˆâ–        | 37/300 [01:10<09:31,  2.17s/it] 13%|â–ˆâ–Ž        | 38/300 [01:11<08:21,  1.91s/it] 13%|â–ˆâ–Ž        | 39/300 [01:12<06:29,  1.49s/it] 13%|â–ˆâ–Ž        | 40/300 [01:14<07:37,  1.76s/it] 14%|â–ˆâ–Ž        | 41/300 [01:15<06:33,  1.52s/it] 14%|â–ˆâ–        | 42/300 [01:16<05:08,  1.19s/it] 14%|â–ˆâ–        | 43/300 [01:20<09:11,  2.14s/it] 15%|â–ˆâ–        | 44/300 [01:21<07:32,  1.77s/it] 15%|â–ˆâ–Œ        | 45/300 [01:21<05:52,  1.38s/it] 15%|â–ˆâ–Œ        | 46/300 [01:26<10:23,  2.46s/it] 16%|â–ˆâ–Œ        | 47/300 [01:28<08:41,  2.06s/it] 16%|â–ˆâ–Œ        | 48/300 [01:28<06:37,  1.58s/it] 16%|â–ˆâ–‹        | 49/300 [01:31<08:23,  2.01s/it] 17%|â–ˆâ–‹        | 50/300 [01:32<07:20,  1.76s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-50
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-50/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-50/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-50/preprocessor_config.json
 17%|â–ˆâ–‹        | 51/300 [01:35<09:02,  2.18s/it] 17%|â–ˆâ–‹        | 52/300 [01:40<11:52,  2.87s/it] 18%|â–ˆâ–Š        | 53/300 [01:41<09:52,  2.40s/it] 18%|â–ˆâ–Š        | 54/300 [01:42<07:33,  1.84s/it] 18%|â–ˆâ–Š        | 55/300 [01:45<09:13,  2.26s/it] 19%|â–ˆâ–Š        | 56/300 [01:46<07:41,  1.89s/it] 19%|â–ˆâ–‰        | 57/300 [01:46<05:53,  1.45s/it] 19%|â–ˆâ–‰        | 58/300 [01:51<09:45,  2.42s/it] 20%|â–ˆâ–‰        | 59/300 [01:52<07:49,  1.95s/it] 20%|â–ˆâ–ˆ        | 60/300 [01:52<06:06,  1.53s/it] 20%|â–ˆâ–ˆ        | 61/300 [01:57<09:54,  2.49s/it] 21%|â–ˆâ–ˆ        | 62/300 [01:58<08:15,  2.08s/it] 21%|â–ˆâ–ˆ        | 63/300 [01:59<06:25,  1.63s/it] 21%|â–ˆâ–ˆâ–       | 64/300 [02:02<08:30,  2.16s/it] 22%|â–ˆâ–ˆâ–       | 65/300 [02:04<07:43,  1.97s/it] 22%|â–ˆâ–ˆâ–       | 66/300 [02:04<06:02,  1.55s/it] 22%|â–ˆâ–ˆâ–       | 67/300 [02:09<09:30,  2.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 68/300 [02:10<07:37,  1.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 69/300 [02:10<06:01,  1.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 70/300 [02:15<09:41,  2.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 71/300 [02:16<07:54,  2.07s/it] 24%|â–ˆâ–ˆâ–       | 72/300 [02:17<05:59,  1.58s/it] 24%|â–ˆâ–ˆâ–       | 73/300 [02:20<07:33,  2.00s/it] 25%|â–ˆâ–ˆâ–       | 74/300 [02:21<06:25,  1.70s/it] 25%|â–ˆâ–ˆâ–Œ       | 75/300 [02:21<05:02,  1.34s/it] 25%|â–ˆâ–ˆâ–Œ       | 76/300 [02:26<08:42,  2.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 77/300 [02:27<07:20,  1.97s/it] 26%|â–ˆâ–ˆâ–Œ       | 78/300 [02:27<05:47,  1.57s/it] 26%|â–ˆâ–ˆâ–‹       | 79/300 [02:31<07:56,  2.16s/it] 27%|â–ˆâ–ˆâ–‹       | 80/300 [02:32<06:50,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 81/300 [02:33<05:17,  1.45s/it] 27%|â–ˆâ–ˆâ–‹       | 82/300 [02:37<08:31,  2.34s/it] 28%|â–ˆâ–ˆâ–Š       | 83/300 [02:38<07:20,  2.03s/it] 28%|â–ˆâ–ˆâ–Š       | 84/300 [02:39<05:39,  1.57s/it] 28%|â–ˆâ–ˆâ–Š       | 85/300 [02:42<07:16,  2.03s/it] 29%|â–ˆâ–ˆâ–Š       | 86/300 [02:43<06:04,  1.70s/it] 29%|â–ˆâ–ˆâ–‰       | 87/300 [02:43<04:47,  1.35s/it] 29%|â–ˆâ–ˆâ–‰       | 88/300 [02:46<06:27,  1.83s/it] 30%|â–ˆâ–ˆâ–‰       | 89/300 [02:47<05:26,  1.55s/it] 30%|â–ˆâ–ˆâ–ˆ       | 90/300 [02:48<04:20,  1.24s/it] 30%|â–ˆâ–ˆâ–ˆ       | 91/300 [02:52<07:52,  2.26s/it] 31%|â–ˆâ–ˆâ–ˆ       | 92/300 [02:54<06:40,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 93/300 [02:54<05:12,  1.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 94/300 [02:57<06:58,  2.03s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 95/300 [02:59<06:23,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 96/300 [02:59<04:59,  1.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 97/300 [03:04<08:31,  2.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 98/300 [03:05<06:54,  2.05s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 99/300 [03:06<05:13,  1.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 100/300 [03:09<06:49,  2.05s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-100
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-100/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-100/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-100/preprocessor_config.json
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 101/300 [03:12<08:09,  2.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 102/300 [03:13<06:12,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 103/300 [03:17<08:38,  2.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 104/300 [03:19<07:12,  2.21s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 105/300 [03:19<05:25,  1.67s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 106/300 [03:24<08:19,  2.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 107/300 [03:25<06:56,  2.16s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 108/300 [03:25<05:12,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 109/300 [03:28<06:10,  1.94s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 110/300 [03:29<05:11,  1.64s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 111/300 [03:29<04:10,  1.33s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 112/300 [03:33<06:09,  1.97s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 113/300 [03:34<05:22,  1.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 114/300 [03:35<04:13,  1.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 115/300 [03:39<07:23,  2.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 116/300 [03:40<06:08,  2.00s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 117/300 [03:41<04:46,  1.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 118/300 [03:44<06:13,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 119/300 [03:45<05:11,  1.72s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 120/300 [03:46<04:07,  1.37s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 121/300 [03:50<07:06,  2.38s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 122/300 [03:52<06:03,  2.04s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 123/300 [03:52<04:42,  1.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 124/300 [03:55<05:44,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 125/300 [03:56<04:54,  1.68s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 126/300 [03:57<03:52,  1.34s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 127/300 [04:01<06:30,  2.25s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 128/300 [04:02<05:33,  1.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 129/300 [04:03<04:16,  1.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 130/300 [04:06<05:39,  2.00s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 131/300 [04:07<04:42,  1.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/300 [04:07<03:40,  1.31s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/300 [04:10<05:11,  1.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/300 [04:11<04:29,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 135/300 [04:12<03:32,  1.29s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 136/300 [04:16<06:01,  2.20s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 137/300 [04:17<05:00,  1.84s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 138/300 [04:18<03:55,  1.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 139/300 [04:21<05:42,  2.13s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 140/300 [04:23<04:51,  1.82s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 141/300 [04:23<03:43,  1.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 142/300 [04:28<06:15,  2.37s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 143/300 [04:29<05:26,  2.08s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 144/300 [04:30<04:15,  1.64s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 145/300 [04:33<05:23,  2.09s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 146/300 [04:34<04:29,  1.75s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 147/300 [04:34<03:32,  1.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 148/300 [04:39<06:05,  2.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 149/300 [04:40<05:12,  2.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 150/300 [04:41<03:59,  1.60s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-150
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-150/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-150/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-150/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-50] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 151/300 [04:49<08:32,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 152/300 [04:50<06:40,  2.70s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 153/300 [04:50<05:02,  2.06s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 154/300 [04:53<05:56,  2.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 155/300 [04:55<05:02,  2.09s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 156/300 [04:55<03:50,  1.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 157/300 [05:00<06:06,  2.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 158/300 [05:01<04:55,  2.08s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 159/300 [05:01<03:46,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 160/300 [05:05<05:03,  2.17s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 161/300 [05:06<04:11,  1.81s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 162/300 [05:06<03:10,  1.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/300 [05:09<04:14,  1.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/300 [05:10<03:43,  1.64s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 165/300 [05:11<02:56,  1.31s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 166/300 [05:16<05:11,  2.32s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 167/300 [05:17<04:16,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 168/300 [05:17<03:13,  1.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 169/300 [05:22<05:17,  2.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 170/300 [05:23<04:27,  2.05s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 171/300 [05:23<03:24,  1.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 172/300 [05:27<04:32,  2.13s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 173/300 [05:28<03:47,  1.79s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 174/300 [05:28<02:58,  1.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 175/300 [05:32<04:08,  1.99s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 176/300 [05:33<03:32,  1.72s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 177/300 [05:33<02:42,  1.32s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 178/300 [05:36<03:20,  1.65s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 179/300 [05:37<03:03,  1.52s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 180/300 [05:37<02:28,  1.24s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 181/300 [05:42<04:28,  2.26s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 182/300 [05:43<03:37,  1.84s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 183/300 [05:43<02:51,  1.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 184/300 [05:48<04:43,  2.44s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 185/300 [05:49<04:02,  2.11s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 186/300 [05:50<03:04,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 187/300 [05:53<04:02,  2.15s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 188/300 [05:54<03:26,  1.84s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 189/300 [05:55<02:38,  1.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 190/300 [05:58<03:27,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 191/300 [05:59<02:55,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 192/300 [05:59<02:17,  1.27s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 193/300 [06:03<03:18,  1.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 194/300 [06:04<02:58,  1.68s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 195/300 [06:04<02:21,  1.35s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 196/300 [06:08<03:43,  2.15s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 197/300 [06:09<03:06,  1.81s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 198/300 [06:10<02:24,  1.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 199/300 [06:15<04:04,  2.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 200/300 [06:16<03:19,  2.00s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-200
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-200/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-200/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-200/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-100] due to args.save_total_limit
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 201/300 [06:19<03:57,  2.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 202/300 [06:22<04:17,  2.63s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 203/300 [06:23<03:28,  2.15s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 204/300 [06:24<02:38,  1.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 205/300 [06:28<04:02,  2.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 206/300 [06:30<03:22,  2.15s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 207/300 [06:30<02:35,  1.67s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 208/300 [06:33<03:05,  2.01s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 209/300 [06:34<02:42,  1.79s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 210/300 [06:35<02:06,  1.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 211/300 [06:39<03:30,  2.36s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 212/300 [06:40<02:52,  1.96s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 213/300 [06:41<02:14,  1.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 214/300 [06:44<02:59,  2.09s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 215/300 [06:46<02:35,  1.83s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 216/300 [06:46<02:01,  1.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 217/300 [06:51<03:20,  2.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 218/300 [06:52<02:44,  2.01s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 219/300 [06:52<02:06,  1.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 220/300 [06:56<02:46,  2.08s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 221/300 [06:57<02:20,  1.77s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 222/300 [06:57<01:49,  1.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 223/300 [07:00<02:30,  1.96s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 224/300 [07:01<02:06,  1.67s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 225/300 [07:02<01:37,  1.29s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 226/300 [07:06<02:49,  2.29s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 227/300 [07:08<02:23,  1.96s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 228/300 [07:08<01:49,  1.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 229/300 [07:11<02:26,  2.06s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 230/300 [07:12<02:01,  1.73s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 231/300 [07:13<01:32,  1.34s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 232/300 [07:18<02:39,  2.35s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 233/300 [07:19<02:16,  2.03s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 234/300 [07:19<01:42,  1.56s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 235/300 [07:22<02:02,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 236/300 [07:23<01:40,  1.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 237/300 [07:23<01:18,  1.24s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 238/300 [07:28<02:23,  2.32s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 239/300 [07:29<02:00,  1.98s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 240/300 [07:30<01:31,  1.53s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 241/300 [07:34<02:24,  2.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 242/300 [07:36<01:59,  2.06s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 243/300 [07:36<01:29,  1.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 244/300 [07:39<01:56,  2.08s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 245/300 [07:40<01:36,  1.76s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 246/300 [07:41<01:16,  1.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 247/300 [07:46<02:09,  2.45s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 248/300 [07:47<01:47,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 249/300 [07:47<01:21,  1.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 250/300 [07:50<01:39,  2.00s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-250/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-150] due to args.save_total_limit
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 251/300 [07:54<02:07,  2.59s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 252/300 [07:55<01:35,  1.98s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 253/300 [08:00<02:12,  2.81s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 254/300 [08:01<01:46,  2.32s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 255/300 [08:01<01:19,  1.78s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 256/300 [08:06<01:54,  2.60s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 257/300 [08:07<01:35,  2.21s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 258/300 [08:08<01:12,  1.72s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 259/300 [08:10<01:23,  2.03s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 260/300 [08:11<01:08,  1.72s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 261/300 [08:12<00:53,  1.38s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 262/300 [08:17<01:27,  2.31s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 263/300 [08:18<01:11,  1.93s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 264/300 [08:18<00:54,  1.53s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 265/300 [08:21<01:12,  2.08s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 266/300 [08:22<00:58,  1.71s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 267/300 [08:23<00:45,  1.37s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 268/300 [08:28<01:16,  2.40s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 269/300 [08:29<01:03,  2.03s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 270/300 [08:29<00:46,  1.56s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 271/300 [08:34<01:13,  2.52s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 272/300 [08:35<00:58,  2.10s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 273/300 [08:36<00:43,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 274/300 [08:40<01:05,  2.53s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 275/300 [08:41<00:51,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 276/300 [08:42<00:38,  1.59s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 277/300 [08:45<00:47,  2.06s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 278/300 [08:46<00:38,  1.77s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 279/300 [08:47<00:29,  1.40s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 280/300 [08:51<00:46,  2.34s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 281/300 [08:52<00:37,  1.97s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 282/300 [08:53<00:27,  1.52s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 283/300 [08:56<00:34,  2.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 284/300 [08:57<00:28,  1.81s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 285/300 [08:58<00:21,  1.45s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 286/300 [09:03<00:34,  2.44s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 287/300 [09:04<00:27,  2.10s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 288/300 [09:04<00:19,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 289/300 [09:08<00:23,  2.16s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 290/300 [09:09<00:18,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 291/300 [09:10<00:13,  1.46s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 292/300 [09:13<00:16,  2.05s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 293/300 [09:14<00:12,  1.78s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 294/300 [09:15<00:08,  1.38s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 295/300 [09:19<00:11,  2.32s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 296/300 [09:20<00:07,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 297/300 [09:20<00:04,  1.47s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 298/300 [09:25<00:04,  2.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 299/300 [09:26<00:02,  2.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [09:27<00:00,  1.60s/it]Saving model checkpoint to /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-300
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-300/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-300/pytorch_model.bin
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-300/preprocessor_config.json
Deleting older checkpoint [/srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/checkpoint-200] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [09:30<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [09:30<00:00,  1.90s/it]
Configuration saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/config.json
Model weights saved in /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/pytorch_model.bin
loading feature extractor configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/preprocessor_config.json
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/added_tokens.json. We won't load it.
Didn't find file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/tokenizer.json. We won't load it.
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/vocab.json
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/tokenizer_config.json
loading file None
loading file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/special_tokens_map.json
loading file None
loading configuration file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/config.json
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "mean",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715/pytorch_model.bin
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /srv/scratch/z5160268/2020_TasteofResearch/kaldi/egs/renee_thesis/s5/myST_local/wav2vec2-base-myST-20210715.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:13,  7.39ex/s]  5%|â–Œ         | 5/100 [00:00<00:10,  9.30ex/s]  7%|â–‹         | 7/100 [00:00<00:09, 10.20ex/s] 10%|â–ˆ         | 10/100 [00:00<00:07, 12.49ex/s] 12%|â–ˆâ–        | 12/100 [00:00<00:07, 11.89ex/s] 14%|â–ˆâ–        | 14/100 [00:00<00:06, 12.30ex/s] 16%|â–ˆâ–Œ        | 16/100 [00:01<00:06, 12.98ex/s] 18%|â–ˆâ–Š        | 18/100 [00:01<00:05, 14.07ex/s] 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:05, 13.47ex/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:01<00:04, 15.51ex/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:01<00:06, 11.05ex/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:01<00:06, 12.14ex/s] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:02<00:04, 14.19ex/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:02<00:04, 14.69ex/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:04, 13.56ex/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:04, 13.98ex/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:02<00:04, 15.03ex/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:02<00:03, 15.35ex/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:02<00:03, 15.88ex/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:03<00:03, 17.13ex/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:03<00:03, 14.08ex/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:03<00:03, 12.36ex/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:03<00:03, 12.05ex/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:03<00:04,  9.72ex/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:04<00:03, 11.27ex/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:04<00:04,  8.67ex/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:04<00:03, 10.37ex/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:04<00:03, 10.57ex/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:04<00:03, 11.05ex/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:04<00:02, 12.24ex/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:05<00:03, 10.20ex/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:05<00:02,  9.41ex/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:05<00:02, 10.80ex/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:06<00:02, 10.40ex/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:06<00:01, 11.83ex/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:06<00:01, 14.36ex/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:06<00:01, 13.39ex/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:06<00:01, 13.21ex/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:06<00:00, 14.99ex/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:06<00:00, 18.13ex/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:07<00:00, 18.09ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 13.97ex/s]
loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/preprocessor_config.json from cache at /home/z5160268/.cache/huggingface/transformers/07e398f6c4f4eb4f676c75befc5ace223491c79cea1109fb4029751892d380a1.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}

loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
loading configuration file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json from cache at /home/z5160268/.cache/huggingface/transformers/cbb3014bb9f03ead9b94f4a791ff8e777465307670e85079d35e28cbc5d88727.0e2d739358c9b58747bd19db5f9f4320dacabbeb1e6282f5cc1069c5c55a82d2
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base-960h",
  "activation_dropout": 0.1,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForCTC"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_dropout": 0.0,
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.1,
  "mask_feature_length": 10,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_prob": 0.05,
  "model_type": "wav2vec2",
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "transformers_version": "4.8.2",
  "vocab_size": 32
}

loading weights file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin from cache at /home/z5160268/.cache/huggingface/transformers/4cb133d3cf3e58e8a4e088b1fc826611a3bcf3d98b20a0bb49ce8cd5362411b7.beeaccfa4baf44ba6123c23938d8a17f48344361a5e7041782e537dfd78a2037
All model checkpoint weights were used when initializing Wav2Vec2ForCTC.

Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json from cache at /home/z5160268/.cache/huggingface/transformers/02595a4ae02bcd3f20d5fe783417b9b4ee9d11c244df7e3108bde6c2f37402da.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer_config.json from cache at /home/z5160268/.cache/huggingface/transformers/a2973721f0d595de6a1c43e48e80dab25bb6c707d364f85a6674c75859942183.b10dd18eae95dde984b32c748781505f0b8c9c20dd067fe083088149f66987c4
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/special_tokens_map.json from cache at /home/z5160268/.cache/huggingface/transformers/208086b2429fa2ba5b196810c1bcd7d61e2c8d4afd65d05d0670096d735fd5bb.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd
loading file https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tokenizer.json from cache at None
  0%|          | 0/100 [00:00<?, ?ex/s]  1%|          | 1/100 [00:00<00:26,  3.70ex/s]  4%|â–         | 4/100 [00:00<00:19,  4.96ex/s]  6%|â–Œ         | 6/100 [00:00<00:14,  6.27ex/s]  9%|â–‰         | 9/100 [00:00<00:11,  7.89ex/s] 11%|â–ˆ         | 11/100 [00:00<00:10,  8.75ex/s] 14%|â–ˆâ–        | 14/100 [00:01<00:08, 10.32ex/s] 16%|â–ˆâ–Œ        | 16/100 [00:01<00:07, 11.47ex/s] 18%|â–ˆâ–Š        | 18/100 [00:01<00:06, 13.02ex/s] 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:06, 13.01ex/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:01<00:04, 15.42ex/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:01<00:06, 11.04ex/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:01<00:05, 12.51ex/s] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:02<00:04, 15.00ex/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:02<00:04, 15.52ex/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:04, 14.38ex/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:04, 14.77ex/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:02<00:03, 15.87ex/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:02<00:03, 16.42ex/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:02<00:03, 16.91ex/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:03<00:02, 18.28ex/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:03<00:03, 14.87ex/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:03<00:03, 12.95ex/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:03<00:03, 12.65ex/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:03<00:04, 10.27ex/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:03<00:03, 11.99ex/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:04<00:04,  9.31ex/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:04<00:03, 10.25ex/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:04<00:03, 10.79ex/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:04<00:02, 12.79ex/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:05<00:02, 10.85ex/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:05<00:02,  9.92ex/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:05<00:02, 11.32ex/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:05<00:02, 10.77ex/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:05<00:01, 12.29ex/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:06<00:01, 14.99ex/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:06<00:01, 14.18ex/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:06<00:01, 12.60ex/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [00:06<00:00, 15.09ex/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:06<00:00, 18.72ex/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [00:06<00:00, 17.92ex/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:06<00:00, 14.49ex/s]
--> Prepared dataset saved at: /srv/scratch/chacmod/renee_thesis/datasetdict-short
To reload this set, run datasetdictName.load_from_dict(myST_datasetdict_fp)
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> STARTING TRAINING... ----------------------------------------- 

{'train_runtime': 570.3757, 'train_samples_per_second': 10.519, 'train_steps_per_second': 0.526, 'train_loss': 0.9740414428710937, 'epoch': 20.0}

------> EVALUATING MODEL... ------------------------------------------ 

--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.279
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0                   YOU USE EM TO M MEASURE THE MASS                     YOU USE EM TO MEASURE THE MASS
1  YEAH WE WE D DON'T REALLY DO IT WITH ANYTHING ...  YER WE WE DON'T REALLY DO WITH ANYTHING ELSE B...
2                                               YEAH                                                 YE
3                                               YEAH                                             YEAHNO
4  NO WE HA WE PULL IT UP AND THEN WE PUSH IT DOW...  NO YEH WE PULL IT UP UP AND THEN WE PUSH IT DO...
5                                       THAT SLIPPED                                               AWIP
6                                        UH HUH YEAH                                              HI AM
7  YEAH NO IT WAS A MILLILIT NO A HUNDRED MILLILI...  YEAHNO IT WAS A MILLER LEAT NO A HUNDRED MILL ...
8  UM YOU DON'T GET THE SAME MEASUREMENT YEAH YEA...  UM YOU DON'T GET THE SAME MEASUREMENTYEAHYEAH ...
9  THE WATER INSIDE THE SPONGE CAUSE WE WANTED TO...  THE WATER INSIDE THIS ONE BBECAUSE WE WANTED T...
--> Taking a deeper look...
<pad> <pad> Y Y <pad> <pad> <pad> E A A H H <pad> <pad> | <pad> W <pad> <pad> E <pad> <pad> | <pad> W <pad> R R <pad> O <pad> <pad> T <pad> E <pad> | <pad> O U <pad> R E <pad> <pad> | | <pad> N <pad> <pad> U M <pad> <pad> B <pad> E R R <pad> E D <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O U <pad> <pad> <pad> <pad> T <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y <pad> <pad> <pad> E A A <pad> H <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

--> Getting baseline test results...
Baseline Test WER: 0.318
--> Showing some baseline prediction errors...
                                         target_text                                           pred_str
0                                               YEAH                                             YES NO
1                                               YEAH                                                YES
2                                          WAIT WHAT                                          WAIT WHAT
3                                                YES                                                YES
4  MMM WHEN YOU LIKE HAVE SOME WATER YOU WANNA KN...  WHEN YOU LIKE HAVE SOME WATER YOU WANT TO KNOW...
5  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...  WELL IF YOU THINK OF IT THESE THESE TWO EQUAL ...
6                                               YEAH                                           MONSIEUR
7                         FOR WAIT UM YEAH BASICALLY                              OF WHICH HUM AR BASIC
8                          I HAVEN'T GOT TO THAT YET                          I HAVEN'T GOT TO THAT YET
9                                                YUP                                                 IF
--> Taking a deeper look...
<pad> <pad> <pad> Y <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> | | W <pad> <pad> E <pad> <pad> | <pad> W R R <pad> <pad> O O <pad> T <pad> E <pad> | <pad> <pad> O U R R | | | | <pad> N <pad> U M <pad> <pad> <pad> B <pad> E R R <pad> <pad> <pad> | <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O W <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O N <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> | <pad> <pad> <pad> <pad> <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E U <pad> <pad> <pad> | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> P <pad> <pad> <pad> A A <pad> <pad> <pad> P <pad> <pad> E R R <pad> | | | <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 15/07/2021 15:23:38
